<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="application/xml; charset=UTF-8">
      <title>TUTORIAL PREVIEW</title>
      <style xml:space="preserve" type="text/css">
.toc { font-size: 70%; padding: 0.4em; outline: thin solid black; margin: 0.4em 0em; width: fit-content; counter-reset: lessonNo 0; font-family: sans-serif }
.toc * { margin: 0em; font-weight: normal }
.toc div { margin: 0.2em; margin-left: 1em; outline: thin solid grey; height: fit-content }
.toc .lesson { display: grid; grid-template-columns: 1fr repeat(3,3fr); counter-increment: lessonNo 1; padding: 0.8em }
.toc .lesson:nth-child(even) { background-color: lightsteelblue }
.toc div.lesson:before { content: attr(class) ' ' counter(lessonNo) ': ' attr(name); background-color: lavender; color: midnightblue; padding: 0.2em; font-family: sans-serif; display: inline-block; height: fit-content }
.toc .unit { clamp(12vw, 100%, 24vw) }
section section section { margin: 0.2em; margin-left: 1em; padding-left: 0.6em; border-left: medium solid grey }

table { width: 80vw; resize: horizontal; padding: 0.8em; background-color: whitesmoke; position: relative; border: thin solid grey; overflow: auto; display: inherit }
tr:nth-child(even) { background-color: gainsboro }


th { width: clamp(10em, auto, 40em) }
td { width: clamp(10em, auto, 40em); border-top: thin solid grey }

section.unit   { width: clamp(45ch, 50%, 75ch); padding: 0.8em; outline: thin solid black; margin: 0.6em 0em }
section.unit h1:first-child { margin-top: 0em }
.observer { background-color: honeydew ; grid-column: 2 }
.maker    { background-color: seashell ; grid-column: 3 }
.learner  { background-color: aliceblue; grid-column: 4 }                 
           
span.wordcount { font-size: smaller; font-weight: bolder; font-style: italic; break-inside: avoid }
span.wordcount.over { color: darkred }

</style>
   </head>
   <body>
      <div class="toc">
         <div class="lesson"
              id="toc-acquire"
              name="acquire">
            <div class="unit observer"
                 id="toc-acquire_101"
                 data-track="observer">
               <h1>101: Project setup and installation<span class="wordcount okay"> (~1315)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Step One: Setup</h2>
                  <div>
                     <h3>Shortcut</h3>
                  </div>
               </div>
               <div>
                  <h2>Step Two: Confirm</h2>
               </div>
               <div>
                  <h2>Comments / review</h2>
                  <div>
                     <h3>Tweaks</h3>
                  </div>
               </div>
            </div>
            <div class="unit maker"
                 id="toc-acquire_102"
                 data-track="maker">
               <h1>102: Examining the setup<span class="wordcount okay"> (~749)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Step One: Inspect the pipelines</h2>
               </div>
               <div>
                  <h2>Step Two: Modify the pipelines</h2>
               </div>
               <div>
                  <h2>For consideration</h2>
               </div>
            </div>
            <div class="unit learner"
                 id="toc-acquire_599"
                 data-track="learner">
               <h1>599: Meeting XProc<span class="wordcount okay"> (~351)</span>
               </h1>
               <div>
                  <h2>Some observations</h2>
               </div>
               <div>
                  <h2>Declarative markup in action</h2>
               </div>
            </div>
         </div>
         <div class="lesson"
              id="toc-walkthrough"
              name="walkthrough">
            <div class="unit observer"
                 id="toc-walkthrough_101"
                 data-track="observer">
               <h1>101: Unpacking XProc 3.0<span class="wordcount over"> (~2680)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Resources</h2>
                  <div>
                     <h3>For reference</h3>
                  </div>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>A closer look</h2>
               </div>
               <div>
                  <h2>Survey</h2>
                  <div>
                     <h3>TEST-XPROC3</h3>
                  </div>
                  <div>
                     <h3>TEST-XSLT</h3>
                  </div>
                  <div>
                     <h3>TEST-SCHEMATRON</h3>
                  </div>
                  <div>
                     <h3>TEST-XSPEC</h3>
                  </div>
               </div>
               <div>
                  <h2>A not-so-simple pipeline</h2>
                  <div>
                     <h3>PRODUCE-PROJECTS-ELEMENTLIST</h3>
                  </div>
               </div>
               <div>
                  <h2>XML syntax, XPath and XProc</h2>
               </div>
               <div>
                  <h2>Learning more about XProc</h2>
               </div>
            </div>
            <div class="unit maker"
                 id="toc-walkthrough_102"
                 data-track="maker">
               <h1>102: XProc fundamentals<span class="wordcount okay"> (~1454)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Learning more about XProc</h2>
               </div>
               <div>
                  <h2>Details details!</h2>
                  <div>
                     <h3>TEST-XSPEC</h3>
                  </div>
                  <div>
                     <h3>PRODUCE-PROJECTS-ELEMENTLIST.xpl</h3>
                  </div>
               </div>
               <div>
                  <h2>Messing around</h2>
                  <div>
                     <h3>Disabling your code</h3>
                  </div>
               </div>
               <div>
                  <h2>Take note</h2>
                  <div>
                     <h3>Where are these downloads coming from?</h3>
                  </div>
                  <div>
                     <h3>Syntax tips</h3>
                  </div>
               </div>
            </div>
            <div class="unit learner"
                 id="toc-walkthrough_399"
                 data-track="learner">
               <h1>399: XProc, XML and XDM  (the XML Data Model)<span class="wordcount over"> (~2107)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>XProc as XML</h2>
                  <div>
                     <h3>Survey of XProc elements</h3>
                  </div>
               </div>
               <div>
                  <h2>XML and the XDM: context and rationale</h2>
               </div>
               <div>
                  <h2>Snapshot history: an XML time line</h2>
               </div>
               <div>
                  <h2>XPath</h2>
                  <div>
                     <h3>Documents and data</h3>
                  </div>
                  <div>
                     <h3>XPath illustrative examples</h3>
                  </div>
               </div>
               <div>
                  <h2>Exercise: Discussion board</h2>
               </div>
            </div>
            <div class="unit learner"
                 id="toc-walkthrough_401"
                 data-track="learner">
               <h1>401 - XSLT Forward and Back<span class="wordcount okay"> (~1499)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Resources</h2>
                  <div>
                     <h3>XSLT 1.0 and XPath 1.0</h3>
                  </div>
                  <div>
                     <h3>XSLT 2.0 and XQuery 1.0</h3>
                  </div>
                  <div>
                     <h3>XSLT 3.0, XQuery 3.0, XPath 3.1</h3>
                  </div>
               </div>
               <div>
                  <h2>XSLT: XSL (XML Stylesheet Language) Transformations</h2>
                  <div>
                     <h3>Running XSLT without XProc</h3>
                  </div>
               </div>
               <div>
                  <h2>Using XSLT in XProc: avoiding annoyances XXX</h2>
                  <div>
                     <h3>Text and attribute value syntax in embedded XSLT</h3>
                  </div>
                  <div>
                     <h3>Namespaces in and for your XSLT</h3>
                  </div>
               </div>
               <div>
                  <h2>Learning XSLT the safer way</h2>
               </div>
               <div>
                  <h2>XProc without XSLT?</h2>
               </div>
               <div>
                  <h2>XProc, XDM (the XML data model) and the standards stack</h2>
               </div>
            </div>
         </div>
         <div class="lesson"
              id="toc-oscal-convert"
              name="oscal-convert">
            <div class="unit observer"
                 id="toc-oscal-convert_101"
                 data-track="observer">
               <h1>101: OSCAL from XML to JSON and back<span class="wordcount okay"> (~1203)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Step zero: an identity pipeline</h2>
               </div>
               <div>
                  <h2>Step zero-point-five: XML to JSON and back</h2>
               </div>
               <div>
                  <h2>Step one: convert some OSCAL XML into OSCAL JSON</h2>
                  <div>
                     <h3>The playing field is the internet</h3>
                  </div>
                  <div>
                     <h3>Consider the options</h3>
                  </div>
               </div>
               <div>
                  <h2>Step two: return trip</h2>
               </div>
               <div>
                  <h2>What is this XSLT?</h2>
               </div>
               <div>
                  <h2>What could possibly go wrong?</h2>
                  <div>
                     <h3>Intercepting errors</h3>
                  </div>
               </div>
            </div>
            <div class="unit maker"
                 id="toc-oscal-convert_102"
                 data-track="maker">
               <h1>102: Hands on data conversions<span class="wordcount okay"> (~1526)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Some breaking and making</h2>
               </div>
               <div>
                  <h2>Value templates in attributes and text: { expr }</h2>
               </div>
               <div>
                  <h2>Designating an input at runtime by binding input ports</h2>
                  <div>
                     <h3>Binding to input ports vs p:load steps</h3>
                  </div>
               </div>
               <div>
                  <h2>Identity pipeline testbed</h2>
                  <div>
                     <h3>0.01 - what is a <q>document</q>
                     </h3>
                     <h3>0.1 - loading documents known or determinable in advance</h3>
                     <h3>0.2 - binding a document to an input port</h3>
                     <h3>0.3 - loading documents dynamically on discovery with <code>p:directory-list</code>
                     </h3>
                     <h3>0.4 - saving results to the file system</h3>
                     <h3>0.5 - exposing results on an output port</h3>
                  </div>
               </div>
               <div>
                  <h2>Probing error space - data conversions</h2>
                  <div>
                     <h3>Converting broken XML or JSON</h3>
                  </div>
                  <div>
                     <h3>Converting broken OSCAL</h3>
                  </div>
                  <div>
                     <h3>Converting not-OSCAL</h3>
                  </div>
               </div>
               <div>
                  <h2>XProc diagnostic how-to</h2>
                  <div>
                     <h3>Emitting runtime messages</h3>
                  </div>
                  <div>
                     <h3>Saving out interim results</h3>
                  </div>
               </div>
               <div>
                  <h2>Validate early and often</h2>
               </div>
            </div>
            <div class="unit learner"
                 id="toc-oscal-convert_201"
                 data-track="learner">
               <h1>201: XProc in more depth<span class="wordcount over"> (~3523)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Overview: the anatomy of an XProc pipeline</h2>
                  <div>
                     <h3>XProc files</h3>
                     <div>
                        <h4>XProc document element</h4>
                     </div>
                     <div>
                        <h4>Namespaces</h4>
                     </div>
                     <div>
                        <h4>@name and @type</h4>
                     </div>
                  </div>
                  <div>
                     <h3>Prologue and body</h3>
                  </div>
                  <div>
                     <h3>XProc steps</h3>
                     <div>
                        <h4>XProc as an XML document</h4>
                     </div>
                     <div>
                        <h4>XProc embedded documentation</h4>
                     </div>
                  </div>
                  <div>
                     <h3>Atomic and compound steps</h3>
                  </div>
                  <div>
                     <h3>Namespaces and extension steps</h3>
                  </div>
                  <div>
                     <h3>Schema for XProc 3.0</h3>
                  </div>
               </div>
               <div>
                  <h2>Some breaking and making</h2>
               </div>
               <div>
                  <h2>What could possibly go wrong?</h2>
                  <div>
                     <h3>Intercepting errors</h3>
                  </div>
               </div>
               <div>
                  <h2>for 599: XProc for JSON</h2>
               </div>
               <div>
                  <h2>for 599: YAML TODO</h2>
               </div>
               <div>
                  <h2>for 599: XProc port bindings</h2>
               </div>
               <div>
                  <h2>for 599: URIs and URI schemes</h2>
               </div>
               <div>
                  <h2>for 599: round tripping as process test</h2>
               </div>
            </div>
            <div class="unit maker"
                 id="toc-oscal-convert_350"
                 data-track="maker">
               <h1>350: Namespaces in XML and XProc<span class="wordcount okay"> (~399)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>XML and namespaces</h2>
               </div>
               <div>
                  <h2>Namespace fixup and namespace cleanup steps</h2>
               </div>
               <div>
                  <h2>Namespace tips and tricks XXX</h2>
                  <div>
                     <h3>Coining new namespaces</h3>
                  </div>
                  <div>
                     <h3>On-the-fly namespace declarations</h3>
                  </div>
                  <div>
                     <h3>Overloading prefixes</h3>
                  </div>
                  <div>
                     <h3>Matching with namespace wildcard</h3>
                  </div>
               </div>
            </div>
            <div class="unit maker"
                 id="toc-oscal-convert_401"
                 data-track="maker">
               <h1>401: XProc, XML, JSON and content types<span class="wordcount okay"> (~296)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Exercise some options</h2>
               </div>
            </div>
            <div class="unit learner"
                 id="toc-oscal-convert_402"
                 data-track="learner">
               <h1>402: XProc, XML, JSON and content types<span class="wordcount okay"> (~1186)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>XProc documents and content types</h2>
                  <div>
                     <h3>XML and XML-like content</h3>
                  </div>
                  <div>
                     <h3>JSON and other text-based formats</h3>
                     <div>
                        <h4>XPath maps, with operators and functions</h4>
                     </div>
                  </div>
                  <div>
                     <h3>Binaries and <q>other</q>
                     </h3>
                  </div>
               </div>
            </div>
         </div>
         <div class="lesson"
              id="toc-courseware"
              name="courseware">
            <div class="unit observer"
                 id="toc-courseware_101"
                 data-track="observer">
               <h1>Courseware 101: Producing this tutorial<span class="wordcount okay"> (~433)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Tutorial production pipelines</h2>
                  <div>
                     <h3>
                        <a href="../../PRODUCE-TUTORIAL-PREVIEW.xpl">PRODUCE-TUTORIAL-PREVIEW</a>
                     </h3>
                  </div>
                  <div>
                     <h3>
                        <a href="../../PRODUCE-TUTORIAL-MARKDOWN.xpl">PRODUCE-TUTORIAL-MARKDOWN</a>
                     </h3>
                  </div>
                  <div>
                     <h3>
                        <a href="../../PRODUCE-TUTORIAL-TOC.xpl">PRODUCE-TUTORIAL-TOC</a>
                     </h3>
                  </div>
                  <div>
                     <h3>
                        <a href="../../PRODUCE-PROJECTS-ELEMENTLIST.xpl">PRODUCE-PROJECTS-ELEMENTLIST</a>
                     </h3>
                  </div>
               </div>
            </div>
            <div class="unit maker"
                 id="toc-courseware_219"
                 data-track="maker">
               <h1>Courseware 219: Learn by Teaching<span class="wordcount okay"> (~395)</span>
               </h1>
               <div>
                  <h2>Goals</h2>
               </div>
               <div>
                  <h2>Prerequisites</h2>
               </div>
               <div>
                  <h2>Resources</h2>
               </div>
               <div>
                  <h2>Improve or enhance a lesson or lesson unit</h2>
                  <div>
                     <h3>Apply Schematron to your edits</h3>
                  </div>
               </div>
               <div>
                  <h2>Create a new lesson unit ('area')</h2>
               </div>
               <div>
                  <h2>Produce a new project and document it with a tutorial</h2>
               </div>
            </div>
         </div>
      </div>
      <section class="lesson"
               id="acquire"
               name="acquire">
         <section class="unit observer"
                  id="acquire_101"
                  data-track="observer">
            <h1>101: Project setup and installation</h1>
            <section>
               <h2>Goals</h2>
               <p>Set up and run an XProc 3.0 pipeline in an XProc 3.0 engine. See the results.</p>
               <p>With a little practice, become comfortable running XProc pipelines, seeing results on a console (command
            line) window as well as in the file system.</p>
               <p>After the first script to get the XProc engine, we use XProc for subsequent downloads. Finishing the setup
            gets you started practicing with the pipelines.</p>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>You have Java installed with a JVM (Java Virtual Machine) available on the command line (a JRE or JDK),
            version 8 (and later).</p>
               <p>
                  <b>Tip:</b> check your Java version from the console using <code>java --version</code>.</p>
               <p>Also, you have a live Internet connection and the capability to download and save resources (binaries and
            code libraries) for local use.</p>
               <p>You are comfortable entering commands on the command line. For installation, you want a <code>bash</code>
            shell if available. On Windows, both WSL (Ubuntu) and Git Bash have been found to work. If you cannot use
               <code>bash</code>, the setup can be done by hand (downloading and unpacking a package from
            SourceForge).</p>
               <p>After installation, subsequent work on Windows does not require <code>bash</code> unless you choose to use
            it – a Windows <code>CMD</code> or Powershell can serve as your environment and the processor invoked with a
            Windows <code>bat</code> file (as described in the documentation). Mac and Linux (and WSL) users can
            continue to use <code>bash</code>.</p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>The setup script is a <code>bash</code> script: <a href="../../../setup.sh">./setup.sh</a>, to be run with
            no arguments. See <a href="../../../setup-notes.md">top-level documentation</a> if you can't use this script
            or if you prefer to download and unzip the dependencies by hand.</p>
               <p>For XProc runtime — to execute pipelines — use either of the scripts <a href="../../../xp3.sh">./xp3.sh</a>
            (under <code>bash</code>) or <a href="../../../xp3.bat">./xp3.bat</a> (for Windows). These scripts are used
            for all pipelines (basically, for everything) unless otherwise noted.</p>
               <p>To perform the setup: first, you download an XProc engine; then you complete setup and testing by running
            these pipelines. They are described in top-level <a href="../../../README.md">README</a> documentation and
            the expected places.</p>
               <ul>
                  <li>
                     <a href="../../../lib/GRAB-SAXON.xpl">lib/GRAB-SAXON.xpl</a>
                  </li>
                  <li>
                     <a href="../../../lib/GRAB-SCHXSLT.xpl">lib/GRAB-SCHXSLT.xpl</a>
                  </li>
                  <li>
                     <a href="../../../lib/GRAB-XSPEC.xpl">lib/GRAB-XSPEC.xpl</a>
                  </li>
                  <li>
                     <a href="../../../smoketest/TEST-XPROC3.xpl">smoketest/TEST-XPROC3.xpl</a>
                  </li>
                  <li>
                     <a href="../../../smoketest/TEST-XSLT.xpl">smoketest/TEST-XSLT.xpl</a>
                  </li>
                  <li>
                     <a href="../../../smoketest/TEST-SCHEMATRON.xpl">smoketest/TEST-SCHEMATRON.xpl</a>
                  </li>
                  <li>
                     <a href="../../../smoketest/TEST-XSPEC.xpl">smoketest/TEST-XSPEC.xpl</a>
                  </li>
               </ul>
            </section>
            <section>
               <h2>Step One: Setup</h2>
               <p>Find setup instructions for the repository in the <a href="../../../README.md">Project README</a> and in the
            linked <a href="../../../setup-notes.md">Setup Notes</a>.</p>
               <p>After reading and reviewing these documents, perform the setup on your system as instructed. To do this you
            can either fork or clone the repository in GitHub or simply download and decompress a zip of the <a href="https://github.com/usnistgov/oscal-xproc3/archive/refs/heads/main.zip">current
            distribution</a>.</p>
               <p>After running the setup script, or performing the installation by hand, make sure you can run all the smoke
            tests successfully.</p>
               <p>As noted in the docs, if you happen already to have <a href="https://www.xml-project.com/morganaxproc-iiise.html">Morgana XProc III</a>, you do not need to
            download it again. Try skipping straight to the smoke tests. You can use a runtime script
               <code>xp3.sh</code> or <code>xp3.bat</code> as a model for your own, and adjust. Any reasonably recent
            version of Morgana should function if configured correctly, and we are interested if it does not. </p>
               <section>
                  <h3>Shortcut</h3>
                  <p>If you want to run through the tutorial exercises but you are unsure of how deeply you will delve, you
               can postpone two of the installations until later:</p>
                  <ul>
                     <li>You will need XSpec only when you want to run tests of stylesheets or queries using the <a href="https://github.com/xspec/xspec">XSpec</a> testing framework</li>
                     <li>You will need SchXSLT only when you want to run Schematron (or XSpec tests of Schematron)</li>
                  </ul>
                  <p>When you see tracebacks suggesting one of these is not supported, you can return to setup.</p>
                  <p>Since almost any pipeline will use XSLT and since we do use the latest version (XSLT 3.0 with XPath 3.1),
               consider the Saxon installation an essential requirement.</p>
               </section>
            </section>
            <section>
               <h2>Step Two: Confirm</h2>
               <p>The top-level README and setup notes also describe testing your installation. Do this next.</p>
               <p>You know things are working in your XProc when two things are happening:</p>
               <ul>
                  <li>On the console, notifications show up with reassuring messages announcing progress</li>
                  <li>When you expect files to be produced for you, they appear, or are updated, as expected</li>
               </ul>
               <p>Both of those will occur with this lesson. The files produced by downloading pipelines are written into the
            project <code>lib</code> directory, as documented. Refresh or restore by deleting the downloaded files and
            running the pipelines to acquire them again.</p>
               <p>Note: you need a live Internet connection for your <code>http</code> requests to go through.</p>
               <p>When you can run all the smoke tests without ugly tracebacks, this lesson is complete.</p>
            </section>
            <section>
               <h2>Comments / review</h2>
               <p>Within this project as a whole, and within its subprojects, everything is done with XProc 3.0, meaning
            everything can be done using a single script, which invokes an XProc processor to read and execute a
            pipeline. This simplicity is at the center of the argument for XProc. </p>
               <p>Effectively (and much more could be said about the processing stack, dependency management and so forth)
            what this means is that XProc offers the user and the developer (in either or both roles) with focused and
            concentrated points of control or points of adjustment. In the field – where software is deployed and used –
            things almost never just <q>drop in</q>. User interfaces, APIs, dependencies and platform quirks: all these
            constrain what users can do, and even developers are rarely free to experiment and explore.</p>
               <p>To the extent this is the case, this project only works if things are actually simple enough to pick up,
            use, learn and adapt.</p>
               <p>
                  <code>xp3.sh</code> and <code>xp3.bat</code> represent attempts at this. Each of them (on its execution
            platform) enables a user to run, without further configuration, the <a href="https://www.xml-project.com/morganaxproc-iiise.html">Morgana XProcIIIse</a> processor on any XProc
            3.0 pipeline, assuming the appropriate platform for each (<code>bash</code> in the case of the shell script,
            Windows batch command syntax for the <code>bat</code> file). Other platforms supporting Java (and hence
            Morgana with its libraries) could be provided with similar scripts.</p>
               <p>Such a script itself must be <q>vanilla</q> and generic: it simply invokes the processor with the designated
            pipeline, and stands back. The logic of operations is entirely encapsulated in the XProc pipeline
            designated. XProc 3.0 is both scalable and flexible enough to open a wide range of possibilities for data
            processing, both XML-based and using other formats such as JSON and plain text. It is the intent of this
            project not to explore and map this space – which is vast – but to show off enough XProc and related logic
            (XSLT, XSpec) to show how this exploration can be done. We are an outfitter at the beginning of what we hope
            will be many profitable voyages to places we have never been.</p>
               <section>
                  <h3>Tweaks</h3>
                  <p>As simple examples, these scripts show only one way of running XProc. Keep in mind that even simple
               scripts can be used in more than one way. </p>
                  <p>For example, a pipeline can be executed from the project root:</p>
                  <pre>$ ./xp3.sh smoketest/TEST-XPROC3.xpl</pre>
                  <p>Alternatively, a pipeline can be executed from its home directory, for example if currently in the
                  <code>smoketest</code> directory (note the path to the script): </p>
                  <pre>$ ../xp3.sh TEST-XPROC3.xpl</pre>
                  <p>This works the same ways on Windows, with adjustments: </p>
                  <pre>&gt; ..\xp3 TEST-XPROC3.xpl </pre>
                  <p>(On Windows a <code>bat</code> file suffix marks it as executable and does not have to be given
               explicitly when called.)</p>
                  <p>Windows users (and others to varying degrees) can set up a drag-and-drop based workflow – using your
               mouse or pointer, select an XProc pipeline file and drag it to a shortcut for the executable (Windows
               batch file). A command window opens to show the operation of the pipeline. See the <a href="../../README.md">README</a> for more information.</p>
                  <p>It is important to try things out since any of these methods can be the basis of a workflow. </p>
                  <p>For the big picture, keep in mind that while the command line is useful for development and demonstration
               – and however familiar XProc itself may become to the developer – to the uninitiated it remains obscure
               and cryptic. XProc-based systems, when integrated into tools or developer editors and environments, can
               look much nicer than tracebacks in a console window. The beauty we are looking for here is in a different
               kind of elegance and power.</p>
               </section>
            </section>
         </section>
         <section class="unit maker"
                  id="acquire_102"
                  data-track="maker">
            <h1>102: Examining the setup</h1>
            <section>
               <h2>Goals</h2>
               <ul>
                  <li>Look at some pipeline organization and syntax on the inside</li>
                  <li>Success and failure invoking XProc pipelines: an early chance to <q>learn to die</q> gracefully (to use the
               gamers' idiom).</li>
               </ul>
            </section>
            <section>
               <h2>Resources</h2>
               <p>Same as <a href="acquire_101_src.html"
                     class="LessonUnit">Setup 101</a>.</p>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>Please complete the repository setup and smoke tests as described in the <a href="acquire_101_src.html"
                     class="LessonUnit">101 lesson</a>. In this lesson, we will run these pipelines with adjustments, or
            similar pipelines.</p>
               <p>This discussion assumes basic knowledge of coding, the Internet (including retrieving resources via
               <code>file</code> and <code>http</code> protocols), and web-based technologies including HTML.</p>
               <p>XML knowledge is also assumed. In particular, XProc uses <a href="https://www.w3.org/TR/xpath-31/">XPath
               3.1</a>, the query language for XML. This latest version of XPath builds on XPath 1.0, so any XPath
            experience will help. In general, any XSLT or XQuery experience will be invaluable.</p>
               <p>You will also need a programmer's plain text editor, XML/XSLT editor or IDE (integrated development
            environment) for more interactive testing of the code.</p>
            </section>
            <section>
               <h2>Step One: Inspect the pipelines</h2>
               <p>The two groupings of pipelines used in setup and testing can be considered separately.</p>
               <p>The key to understanding both groups is to know that once the initial <a href="../../../setup.sh">Setup
               script</a> is run, Morgana can be invoked directly, as paths and scripts are already in place. In doing
            so – before extension libraries are in place – it can use only basic XProc steps, but those are enough to
            start with.</p>
               <p>Specifically, the pipelines can acquire resources from the Internet, save them locally, and perform
            unarchiving (unzipping). Having been downloaded, each library provides software that the pipeline engine
            (Morgana) can use to do more.</p>
               <p>Accordingly, the first group of pipelines (in the <a href="../../../lib/readme.md">lib</a> directory has
            a single purpose, namely (together and separately) to download software to augment Morgana's feature
            set.</p>
               <ul>
                  <li>
                     <a href="../../../lib/GRAB-SAXON.xpl">lib/GRAB-SAXON.xpl</a>
                  </li>
                  <li>
                     <a href="../../../lib/GRAB-SCHXSLT.xpl">lib/GRAB-SCHXSLT.xpl</a>
                  </li>
                  <li>
                     <a href="../../../lib/GRAB-XSPEC.xpl">lib/GRAB-XSPEC.xpl</a>
                  </li>
               </ul>
               <p>Pipelines in a second group work similarly in that each one exercises and tests capabilities provided by
            software downloaded by a member of the first group.</p>
               <ul>
                  <li>
                     <a href="../../../smoketest/TEST-XPROC3.xpl">smoketest/TEST-XPROC3.xpl</a> tests MorganaXProc-III</li>
                  <li>
                     <a href="../../../smoketest/TEST-XSLT.xpl">smoketest/TEST-XSLT.xpl</a> tests Saxon</li>
                  <li>
                     <a href="../../../smoketest/TEST-SCHEMATRON.xpl">smoketest/TEST-SCHEMATRON.xpl</a> tests
               SchXSLT</li>
                  <li>
                     <a href="../../../smoketest/TEST-XSPEC.xpl">smoketest/TEST-XSPEC.xpl</a> tests XSpec</li>
               </ul>
               <p>Take a look at these files. It may be helpful (for those getting used to it) to envision the XML syntax as a
            set of nested frames with labels and connectors.</p>
               <p>Try more than one way of looking at the XProc source code: in the Github repository, on your file system, in
            a plain text editor, in an XML editor.</p>
            </section>
            <section>
               <h2>Step Two: Modify the pipelines</h2>
               <p>Use a text editor or software development application for this exercise.</p>
               <p>If you have any concepts for improvements to the pipelines, or other resources that might be acquired this way, copy and modify one of the pipelines given to achieve those results.</p>
               <p>Even if not: be sure to break the pipelines given – or copies under new names – in any of several ways. Then
            run the modified pipelines, as a <i>safe way</i> to familiarize yourself with error messages:</p>
               <ul>
                  <li>Break the XML syntax of a pipeline and try to run it</li>
                  <li>Leave XML syntax intact (well-formed), but break something in the XProc <ul>
                        <li>An element name, attribute or attribute setting</li>
                        <li>A namespace</li>
                     </ul>
                  </li>
                  <li>Try to retrieve something from a broken link</li>
               </ul>
               <p>Having introduced an error, reverse the damage. Make sure your pipelines are back in working order when this
            exercise is complete.</p>
            </section>
            <section>
               <h2>For consideration</h2>
               <p>Developers coming to this technology need to consider who would use it, and whether it is useful mainly at
            the back end, or also <q>on the shop floor</q>, directly in the hands of professionals who must work with
            the data, bringing expertise in subject matter (such as, for OSCAL, systems security documentation) but not
            in data processing as such.</p>
               <p>Key to this question is not only whether attractive and capable user interfaces (or other mediators) can be
            developed (this is a known problem) but more importantly whether the systems themselves are adaptable enough
            so they can be deployed, used, refitted and maintained not just for repetitive generic tasks, but for
               <i>particular</i>, <i>special</i> and <i>local</i> problems, especially those discoverable only at the
            points where information is gathered and codified.</p>
               <p>This larger fitting of solutions to problems is a responsibility for both SMEs (subject matter experts) and
            software developers together, who must define problems to be solved before approaches to them can be
            found.</p>
               <p>The open questions are: who can use XProc pipelines; and how can they be made more useful? The questions
            come up in an OSCAL context or any context where XML is demonstrably capable.</p>
               <p>Having completed and tested the setup you are ready for work with XProc: proceed to the next lesson.</p>
            </section>
         </section>
         <section class="unit learner"
                  id="acquire_599"
                  data-track="learner">
            <h1>599: Meeting XProc</h1>
            <section>
               <h2>Some observations</h2>
               <p>Because it is now centered on <i>pipelines</i> as much as on files and software packages, dependency
            management is different from other technologies including Java and NodeJS –  how so?</p>
               <p>MorganaXProc-III is implemented in Scala, and Saxon is built in Java, but otherwise distributions including
            the SchXSLT and XSpec distributions consist mainly of XSLT. This is either very good (with development and
            maintenance requirements in view), or not good at all.</p>
               <p>Which is it, and what are the determining variables that tell you XProc is a good fit? How much of this is
            due to the high-level, abstracted nature of <a href="https://en.wikipedia.org/wiki/Fourth-generation_programming_language">4GLs</a> including both XSLT
            3.1 and XProc 3.0? Prior experience with XML-based systems and the problem domains in which they work well
            is probably a factor. How much are the impediments technical, and how much are they due to culture?</p>
               <p>The next lesson unit includes more information on where to learn about XProc and how to become familiar not
            only with its uses in connection with OSCAL, but in general.</p>
            </section>
            <section>
               <h2>Declarative markup in action</h2>
               <p>Considerable care is taken in developing these demonstrations to see to it that the technologies on which we
            depend, notably XProc and XSLT but not limited to these, are both nominally and actually conformant to
            externally specified standard technologies, i.e. XProc and XSLT respectively (as well as others), and
            reliant to the greatest possible extent on well-documented and accessible runtimes.</p>
               <p>It is a tall order to ask that any code base should be both easy to integrate and use with others, and at
            the same time, functionally complete and self-sufficient. Of these two, we are lucky to get one. Because the
            world is complex, we are always throwing in one or another new dependency, along with new rule sets. Here,
            we work by making everything transparent as possible (so nothing is downloaded behind the scenes, for
            example) while also documenting as thoroughly as we can, including with code comments.</p>
               <p>Can any code base be self-explanatory in any meaningful sense? Doubtful. But one can try and leave tracks
            and markers, at least. </p>
            </section>
         </section>
      </section>
      <section class="lesson"
               id="walkthrough"
               name="walkthrough">
         <section class="unit observer"
                  id="walkthrough_101"
                  data-track="observer">
            <h1>101: Unpacking XProc 3.0</h1>
            <section>
               <h2>Goals</h2>
               <ul>
                  <li>More familiarity with XProc 3.0, including some syntax</li>
                  <li>Some awareness of XProc's capabilities, along with context including background history, concepts and
               resources</li>
               </ul>
               <p>If you read only a single page from this tutorial, and you know nothing about XProc, this page could offer
            the most rapid introduction.</p>
               <p>But a further goal is to stimulate a reader's curiosity along with their awareness.</p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>This lesson discusses, in more depth, the same pipelines you ran in setup: <a href="../acquire/acquire_101_src.html"
                     class="LessonUnit">Setup 101</a>, in particular <a href="../../../smoketest/readme.md">the smoke test pipelines</a>.</p>
               <p>Also, this lesson discusses a pipeline used for producing this tutorial: <a href="../../PRODUCE-PROJECTS-ELEMENTLIST.xpl">PRODUCE-PROJECTS-ELEMENTLIST.xpl</a> generates an <a href="../../sequence/element-directory.md">index to XProc in this repository</a>. It is offered as a
            first demonstration (among other things) of XProc applied to XProc.</p>
               <section>
                  <h3>For reference</h3>
                  <p>The <a href="https://xproc.org">XProc.org 3.0 dashboard page</a> is maintained by XProc community
               organizers. It offers a hub for reference materials and community contributions.</p>
                  <p>The last section of this lesson unit describes more reference materials as well.</p>
               </section>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>
                  <b>No prerequisites.</b> The commentary assumes, however:</p>
               <ul>
                  <li>You have run the acquisition, setup and test pipelines <a href="../acquire/acquire_101_src.html"
                        class="LessonUnit">described in the first lesson set</a>, or you are willing to pretend you have done
               so for our purposes here</li>
                  <li>You have some prior experience with either XML technologies, web publishing technologies, data modeling
               and data exchange, or (again) you are open to learning or at least thinking about it</li>
               </ul>
               <p>If you fall into neither of these categories – welcome, and congratulations on your perseverence at least.
            These pages are certainly available to be read and referenced even if you are not running any of the
            software: as part of the resource provided (the repository as a whole), they are open to anyone who finds
            them to be useful, including for specialized purposes.</p>
               <p>So you are also welcome to read what follows if this is your first look at XProc, or if you are not after
            the runtime, only the ideas, or if you have some other use in mind (such as perhaps testing an XProc
            engine?).</p>
               <p>If you fall into this category, however, you should also (one last time!) consider running some of the code
            after all. You might be surprised at how easy and not-so-scary it really is.</p>
            </section>
            <section>
               <h2>A closer look</h2>
               <p>If you have completed <a href="../acquire/acquire_101_src.html"
                     class="LessonUnit">Acquire 102</a> you have
            already inspected the <a href="../../../lib/readme.md">lib</a> and <a href="../../../smoketest/readme.md">smoketest</a> folders, and run the pipelines you have found there. If you haven't, now is a moment to
            catch up. Even if you have decided not to install any software, please look at the pipelines we are using
            for the purpose here.</p>
               <p>Routine code inspection can also be done <a href="https://github.com/usnistgov/oscal-xproc3">on Github</a>
            as well (not a bad idea in any case), not just in a copy of the distribution. If you are reading this in the
            repository, the pipelines files (generally, suffixed <code>xpl</code> by convention) can be inspected in
            another browser window.</p>
               <p>A quick summary of what these pipelines do:</p>
               <ul>
                  <li>
                     <a href="../../../lib/GRAB-SAXON.xpl">lib/GRAB-SAXON.xpl</a> downloads a zip file from a <a href="https://www.saxonica.com/download">Saxonica download site</a>, saves it, and extracts a
                  <code>jar</code> (Java library) file, which it places in the Morgana library directory</li>
                  <li>
                     <a href="../../../lib/GRAB-SCHXSLT.xpl">lib/GRAB-SCHXSLT.xpl</a> downloads a zip file from Github and
               unzips it into a directory where Morgana can find it.</li>
                  <li>
                     <a href="../../../lib/GRAB-XSPEC.xpl">lib/GRAB-XSPEC.xpl</a> also downloads and <q>unarchives</q> a zip
               file resource, this time a copy of <a href="https://github.com/xspec/xspec">an XSpec
               distribution</a>.</li>
               </ul>
               <p>Essentially, these all replicate and capture the work a developer must do to identify and acquire libraries.
            Maintaining our dependencies this way - not quite, but almost <q>by hand</q> -- appears to have benefits for
            system transparency and robustness.</p>
               <p>The second group of pipelines is a bit more interesting. Each of the utilities provided for in packages just
            downloaded is tested by running a <b>smoke test</b>.</p>
               <p>Each smoke test performs a minor task, with the aim of determining whether a simple representative process
            will complete successfully. (When we plug the unit in and switch on the power, can we see and smell smoke?
            Do tracebacks burn your retinas?)</p>
               <ul>
                  <li>
                     <a href="../../../smoketest/TEST-XPROC3.xpl">smoketest/TEST-XPROC3.xpl</a> amounts to an XProc <q>Hello
                  World</q>. In that spirit, feel free to write your own version. (You get another chance to do this <a href="walkthrough_102_src.html"
                        class="LessonUnit">real soon now</a>.)</li>
                  <li>
                     <a href="../../../smoketest/TEST-XSLT.xpl">smoketest/TEST-XSLT.xpl</a> tests Saxon, an XSLT/XQuery
               transformation engine. XSLT and XQuery are related technologies (different languages, same data model)
               developed with XML processing in mind, but in recent years generalized to a wider range of data
               structures.</li>
                  <li>
                     <a href="../../../smoketest/TEST-SCHEMATRON.xpl">smoketest/TEST-SCHEMATRON.xpl</a> tests SchXSLT.
               SchXSLT is an implementation of Schematron, an ISO-standard validation and reporting technology. As this
               implementation relies on XSLT, this library also requires Saxon.</li>
                  <li>
                     <a href="../../../smoketest/TEST-XSPEC.xpl">smoketest/TEST-XSPEC.xpl</a> tests XSpec, an XSLT-based
               testing framework useful for testing deployments of XSLT, XQuery and Schematron.</li>
               </ul>
               <p>Any and each of these can be used as a <q>black box</q> by any competent operator, even without
            understanding the internals. But this simplicity masks and manages complexity. XProc is XProc but its
            capabilities are limited without XSLT, XQuery, Schematron, XSpec and others, an open-ended set of compatible
            and complimentary technologies.</p>
               <p>At the same time, common foundations make it possible to learn these technologies together and in
            tandem.</p>
            </section>
            <section>
               <h2>Survey</h2>
               <p>Each of the test pipelines exercises a simple sequence of operations. Open any XProc file in an editor or
            viewer where you can see the tags. Skim this section to get only a high-level view.</p>
               <p>The aim here is demystification. Understand the parts to understand the whole. Reading the element names
            also inscribes them in memory circuits where they can be recovered.</p>
               <section>
                  <h3>TEST-XPROC3</h3>
                  <p>Examine the pipeline <a href="../../../smoketest/TEST-XPROC3.xpl">TEST-XPROC3.xpl</a>. It breaks down as
               follows:</p>
                  <ul>
                     <li>
                        <code>p:output</code> – An <em>output port</em> is defined. It specifies that when the process
                  results are delivered, a couple of serialization rules are followed: the text is indented and written
                  without an XML declaration at the top. With this port, the process outputs can be captured by the
                  calling process (such as your script), or simply echoed to the console.</li>
                     <li>
                        <code>p:identity</code> – An <em>identity step</em> does nothing with its input but simply passes it
                  along. This one is a little different from usual in that its inputs are given as literal (XML)
                  contents in the pipeline. Essentially, because this pipeline has this step, it does not need to load
                  or rely on any inputs, because its inputs are given here. The input is a single line of XML.</li>
                     <li>
                        <code>p:namespace-delete</code> – A <em>namespace-delete</em> step is used to strip an XML namespace
                  definition from the document bound to the identity step. This XML inherits namespaces from the
                  pipeline itself, but it has no elements or attributes that use it, so the namespace is unneeded and
                  its declaration comes through as noise. With this step the pipeline results are clean and simple.</li>
                  </ul>
                  <p>When you run this pipeline, the <code>CONGRATULATIONS</code> document given in line will be echoed to the
               console, where designated outputs will appear if not otherwise directed.</p>
               </section>
               <section>
                  <h3>TEST-XSLT</h3>
                  <p>
                     <a href="../../../smoketest/TEST-XSLT.xpl">This pipeline</a> executes a simple XSLT transformation, in
               order to test that XSLT transformations can be successfully executed.</p>
                  <ul>
                     <li>
                        <code>p:output</code> – An output port is designated with <code>p:output</code> as in the <a href="../../../smoketest/TEST-XPROC3.xpl">TEST-XPROC3 pipeline</a>.</li>
                     <li>
                        <code>p:xslt</code> – Instead of providing a literal document in an <em>identity</em> step, this
                  pipeline performs an XSLT transformation. The input to this transformation is given as a literal XML
                  in the same way, except this time it is provided as input to a transformation process defined by an <a href="../../../smoketest/src/congratulations.xsl">XSLT stylesheet</a> called in by the
                  pipeline.</li>
                     <li>
                        <code>p:namespace-delete</code> – The <code>ox</code> namespace is stripped from the result as in <a href="../../../smoketest/TEST-XPROC3.xpl">TEST-XPROC3 pipeline</a>. This could have been done in
                  the XSLT as well, but this way the transformation has one less thing to do or go wrong. More simpler
                  steps prove more legible and tractable than fewer complicated ones.</li>
                  </ul>
                  <p>Like the <a href="../../../smoketest/TEST-XPROC3.xpl">TEST-XPROC3 pipeline</a> this pipeline shows its
               results in the console. This time the result is not just the XML given in the pipeline, but that XML as
               modified by the transformation.</p>
                  <p>If your pipeline execution can't process the XSLT (perhaps Saxon is not installed, or the XSLT itself has
               a problem) you will get an error saying so.</p>
                  <p>Errors in XProc are reported by the Morgana engine using XML syntax. Among other things, this means they
               can be captured and processed in pipelines.</p>
               </section>
               <section>
                  <h3>TEST-SCHEMATRON</h3>
                  <p>Schematron is a language used to specify rules to apply to XML documents. In this case a small Schematron
               is applied to a small XML.</p>
                  <ul>
                     <li>
                        <code>p:output</code> – An output port is designated for the results with the same settings.</li>
                     <li>
                        <code>p:validate-with-schematron</code> – This is an XProc step specifically for evaluating an XML
                  document against the rules of a given Schematron. Like the TEST-XPROC3 and TEST-XSLT` pipelines, this
                  one presents its own input, given as a literal XML document given in the pipeline document (using
                     <code>p:inline</code>). A setting on this step provides for it to throw an error if the document
                  does not conform to the rules. The Schematron file provided as input to this step, <a href="../../../smoketest/src/doing-well.sch">src/doing-well.sch</a>, gives the rules. This flexible
                  technology enables easy testing of XML against rule sets defined either for particular cases in
                  particular workflows, or for entire classes or sets of documents.</li>
                     <li>
                        <code>p:namespace-delete</code> – This step is used here as in the other tests for final cleanup of
                  the information produced.</li>
                  </ul>
               </section>
               <section>
                  <h3>TEST-XSPEC</h3>
                  <p>
                     <a href="https://github.com/xspec/xspec">XSpec</a> is a testing framework for XSLT, XQuery and
               Schematron. It takes the form of a vocabulary and a process (inevitably implemented in XSLT and XQuery)
               for executing queries, transformations, and validations, by running them over known inputs, comparing the
               results to expected results, and reporting the results of this comparison. XProc, built to orchestrate
               manipulations of XML contents, is well suited for running XSpec.</p>
                  <p>An XSpec instance (or <q>document</q>) defines a set of tests for a transformation or query module using
               the XSpec vocabulary. An XSpec implementation executes the tests and delivers the results. Since XSpec,
               like Schematron, reports its findings in XML, XProc can be useful both to manage the inputs and outputs,
               and to process the XSpec reports.</p>
                  <ul>
                     <li>
                        <code>p:import</code> – calls to an external XProc file to make its step definitions available.</li>
                     <li>
                        <code>p:input</code> – works as it does elsewhere, to declare inputs for the pipeline. In this case,
                  the inputs must be XSpec documents using the XSpec vocabulary. You can expect errors when they are
                  not. This testing pipeline offers three different XSpecs to be run, one each for XSLT, XQuery and
                  Schematron.</li>
                     <li>
                        <code>p:for-each</code> – defines a step or sequence of steps to be applied to each input,
                  separately.</li>
                     <li>
                        <code>p:identity</code> – simply passes through the previous step's result. While this is a
                     <q>no-op</q> in the XProc itself, it provides an occasion for a message to help trace the XProc
                  execution.</li>
                  </ul>
                  <p>
                     <a href="walkthrough_102_src.html"
                        class="LessonUnit">The next lesson</a> offers more detail about this
               pipeline.</p>
               </section>
            </section>
            <section>
               <h2>A not-so-simple pipeline</h2>
               <p>
                  <b>tl/dr</b> - examine the Markdown file presenting an <a href="../../sequence/element-directory.md">XProc
               Element directory</a>. It is generated by <a href="../../PRODUCE-PROJECTS-ELEMENTLIST.xpl">a
            pipeline</a>. Examine that pipeline to see XProc with real-world complexity.</p>
               <p>The simple pipelines examined so far show how useful things can be done simply, while the pipeline
            architecture allows for great flexibility.</p>
               <p>Simplicity and flexibility together enable complexity. Once it is factored out, a complex operation can be
            managed and deployed just like a simple one, with its internal complexities masked by a simple and
            predictable interface.</p>
               <p>Next, take a look at a more complex example, the prototype pipeline <a href="../../PRODUCE-PROJECTS-ELEMENTLIST.xpl">PRODUCE-PROJECTS-ELEMENTLIST.xpl</a>. Like the setup and
            smoke-test pipelines, this is a standalone pipeline (requiring no runtime bindings or settings): when this
            plan (<q>step</q> or pipeline) is executed, the processor will acquires inputs, produce results and write
            those results to the file system. The output it generates is stored as <a href="../../sequence/element-directory.md">element-directory.md</a>, a Markdown file (find the
               <code>p:store</code> step).</p>
               <p>The result is a reference resource encoded in Markdown: an index of XProc elements used in pipelines in this
            repository. As Markdown, this result can be reposted back into the repository or viewed with any Markdown
            viewing application. The index lists XProc elements, that is the core of the XProc vocabulary: for any XProc
            element used anywhere among the projects listed, the listing shows the pipelines where it appears. Following
            the index, the resource also shows a list of (repository) project folders in a prescribed order, with their
            XProc files and whatever XProc elements appear <i>first</i> (within the entire sequence up to to point)
            within that file. Among other uses this is helpful for assessing coverage of tutorial lessons as it offers a
            (semi) <i>ordered</i> survey of the elements.</p>
               <p>For example, looking up <code>p:store</code> you can see all the pipelines that contain this common step. Or
            looking at the <code>oscal-convert</code> listing you can see the XProc steps appearing first in that
            project folder.</p>
               <p>To confirm proper functioning, run the pipeline again after deleting or renaming the Markdown result
            file.</p>
               <p>Consider also what other kinds of indexing might be useful. When you modify XProc or add new XProc pipelines
            to the project folders, consider running this pipeline again to update the indexes.</p>
               <p>Open the file and inspect it to get a sense of how it works. The XML syntax is verbose, but not really all
            that frightening. Practice helps! The pipeline is also considered in the <a href="walkthrough_102_src.html"
                     class="LessonUnit">102 Lesson unit</a> segment.</p>
               <section>
                  <h3>PRODUCE-PROJECTS-ELEMENTLIST</h3>
                  <p>The pipeline <a href="../../PRODUCE-PROJECTS-ELEMENTLIST.xpl">PRODUCE-PROJECTS-ELEMENTLIST.xpl</a>
               contains XML comments (<code>&lt;!-- using comment syntax --&gt;</code>) that should help explain its
               operations.</p>
                  <p>There are some significant differences between this pipeline and the small ones we have looked at so
               far.</p>
                  <ul>
                     <li>Of course, it is longer and more complex, reflecting the complexity of the operations it
                  performs.</li>
                     <li>Part of the complexity is due to a two-step process here. First, the file system is surveyed in
                  locations named in an input configuration. Then all those resources (which happen to be XML using the
                  XProc vocabulary) are indexed against the files in which they occur. The two listings are both
                  produced in this second analytical phase, showing how once the files are surveyed, more than one
                  analysis is possible.</li>
                     <li>In particular, the index to <q>first use</q> is not simple. A great deal of the complexity of
                  detailed operations has been off-loaded into XSLT transformation code, which in this pipeline can be
                  seen embedded in the XProc, indeed occupying the greater part of the XML in the file. (About two
                  thirds of the element count: you can usually recognize XSLT by the conventional <code>xsl:</code>
                  element prefix.) This pipeline also has an XSLT called from an external file (toward the end). XProc
                  can provide XSLT either way, and each has its advantages.</li>
                     <li>One good thing about seeing the XSLT here is you can get a good sense of what it looks like, whether
                  embedded or kept externally. XSLT is <a href="walkthrough_401_src.html"
                           class="LessonUnit">not
                     essential to XProc</a>, but it very much expands its practical capabilities.</li>
                  </ul>
               </section>
            </section>
            <section>
               <h2>XML syntax, XPath and XProc</h2>
               <p>Newcomers to XML may feel they are in the deep water with XML syntax.</p>
               <p>In the context of XProc, this is actually not as hard as it looks:</p>
               <ul>
                  <li>All XML files follow the same syntax rules with respect to tags, elements and attributes (names and
               syntax), namespaces, comments etc.</li>
               </ul>
               <pre>&lt;tagged attribute="value"&gt;Information goes here&lt;/tagged&gt;
&lt;!-- comment goes here --&gt; </pre>
               <ul>
                  <li>XML vocabularies are typically qualified with <b>namespaces</b> to show, and to disambiguate, which XML
               application or language they belong to. The namespaces are indicated by name <em>prefixes</em>. So in
               this repository (and conventionally for XProc), any element prefixed <code>p:</code> is an XProc element,
               and another prefix or none indicates an extension or another vocabulary, such as appears in XML being
               processed.</li>
               </ul>
               <pre>&lt;p:output port="result" serialization="map{'indent' : true(), 'omit-xml-declaration': true() }" /&gt;</pre>
               <ul>
                  <li>Embedded in the syntax is another syntax, <em>XPath</em>. This lightweight but powerful query language
               is a formal subset of XQuery. XPath is ubiquitous in XProc, XSLT, Schematron, XSpec etc. In XProc, the
               XPath will ordinarily be given in attributes.</li>
               </ul>
               <pre>&lt;p:output port="result" serialization="<b>map{'indent' : true(), 'omit-xml-declaration': true() }</b>" /&gt;</pre>
               <ul>
                  <li>Learn more about this in the <a href="walkthrough_102_src.html"
                        class="LessonUnit">102 Lesson unit</a> –
               or plunge on, and pick up what you need as you go.</li>
               </ul>
            </section>
            <section>
               <h2>Learning more about XProc</h2>
               <p>This tutorial has a handmade <a href="../../xproc-links.md">XProc links page</a> with links.</p>
               <p>Also, see the official <a href="https://xproc.org">XProc.org dashboard page</a>.</p>
               <p>Also, check out indexing logic offered in the <a href="../../../projects/xproc-doc/readme.md">xproc-doc
               project folder</a>. It has pipelines producing useful indexes to XProc in this repository and in general,
            including one producing an <a href="../../../projects/xproc-doc/XPROC-STEP-INDEX-HTML.xpl">index to XProc
               simple steps</a> in HTML, with code snips.</p>
               <p>There is <a href="https://xmlpress.net/publications/xproc-3-0/">a book, Erik Siegel's <i>XProc 3.0
                  Programmer's Reference</i>
                  </a> (2020) and an <a href="https://xprocref.org/index.html">excellent
               reference site</a> by the same author.</p>
            </section>
         </section>
         <section class="unit maker"
                  id="walkthrough_102"
                  data-track="maker">
            <h1>102: XProc fundamentals</h1>
            <p>
            </p>
            <section>
               <h2>Goals</h2>
               <ul>
                  <li>More familiarity with XProc 3.0, with more syntax</li>
                  <li>Get hands a little dirty – and practice washing up</li>
                  <li>First look at XProc pipeline organization</li>
               </ul>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>You have done <a href="../acquire/acquire_101_src.html"
                     class="LessonUnit">Setup 101</a>, <a href="../acquire/acquire_101_src.html"
                     class="LessonUnit">Setup 102</a> and <a href="walkthrough_101_src.html"
                     class="LessonUnit">Unpack 101</a>.</p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>Take a quick look <i>now</i> (and a longer look later):</p>
               <p>This tutorial's handmade <a href="../../xproc-links.md">XProc links page</a>
               </p>
               <p>Also, the official <a href="https://xproc.org">XProc.org dashboard page</a>
               </p>
               <p>Also, check out XProc index materials produced in this repository: <a href="../../../projects/xproc-doc/readme.md">XProc docs</a>
               </p>
               <p>And the same pipelines you ran in setup: <a href="../acquire/acquire_101_src.html"
                     class="LessonUnit">Setup
               101</a>.</p>
            </section>
            <section>
               <h2>Learning more about XProc</h2>
               <p>A partial list of ways to learn more about XProc:</p>
               <ul>
                  <li>Search engines: use keywords <q>XProc3</q> or <q>XProc 3.0</q> to help distinguish from 1.0
               technologies</li>
                  <li>Resources: <a href="../../xproc-links.md">links</a> here and elsewhere</li>
                  <li>Hands on exercises</li>
                  <li>Work the notes - save out and annotate these pages</li>
               </ul>
            </section>
            <section>
               <h2>Details details!</h2>
               <p>XProc pipelines described in <a href="walkthrough_101_src.html"
                     class="LessonUnit">the previous lesson unit</a>
            contain a few noteworthy features.</p>
               <p> To edit these files, use any XML-capable plain text editor (that is, with care, any editor at all that
            saves text files as UTF-8).</p>
               <section>
                  <h3>TEST-XSPEC</h3>
                  <ul>
                     <li>Where XSpec documents are bound to the input port <code>source</code>, they have
                     <code>content-type='application/xml'</code> given. This is because with the unconventional file
                  suffix <code>xspec</code> (useful for other reasons), the XProc engine needs extra information to know
                  they should be read as XML, not some other data format. Try removing the <code>content-type</code> to
                  see what happens when the engine does not know an XML file is XML.</li>
                     <li>The step <code>p:for-each</code> is not just a step: it also contains steps. It is a <em>compound
                     step</em>. You would be correct to infer this step enables us to perform operations on several
                  inputs in parallel: just what this pipeline needs.</li>
                     <li>Within the <code>p:for-each</code>, the step <code>ox:execute-xspec</code> is named in the
                     <code>ox</code> namespace, which resolves to the string
                     <code>http://csrc.nist.gov/ns/oscal-xproc3</code>, a value assigned for this project. This step is
                  defined in the <a href="../../../xspec/xspec-execute.xpl">imported pipeline</a>. XProc is indefinitely
                  extensible: the namespace feature allows us to create new steps without fear of name clashes with old
                  steps – or steps that are still uninvented and unnamed. We can develop and name steps in our own
                  namespace, while also acquiring and using steps in other namespaces.</li>
                     <li>The <code>p:identity</code> step is used twice in this pipeline for one purpose only: to indicate
                  messages the XProc engine should deliver. In the normal configuration, you should see these messages
                  in the console when the pipeline runs. This is a common use for <code>p:identity</code>.</li>
                     <li>The repository observes a couple of conventions with regard to steps and messages. For example: any
                     <code>p:load</code> or <code>p:save</code> step should have a message; and messages should always
                  be prefixed with a bracketed indicator of the pipeline that issues them, for example the
                     <code>[TEST-XSPEC]</code> messages that are emitted here, once for each input and again once when
                  the pipeline finishes.</li>
                     <li>Yes, those conventions are enforced in the repository by <a href="../../../testing/xproc3-house-rules.sch">a Schematron</a> that can be applied to any
                  pipeline, both in development and when it is committed to the repository under CI/CD (continuous
                  integration / continous development). Assuming we take care to run our tests and validations, this
                  does most of the difficult work maintaining consistency, namely detecting the inconsistency.</li>
                     <li>Reassuring messages aside, no XSpec reports are actually captured by this XProc! With nothing bound
                  to an output port, it <em>sinks</em> by default. That is because it is a smoke test, and we care only
                  to see that it runs and completes without error. The inputs are all controlled, so we know what those
                  reports say. Or we can find out.</li>
                  </ul>
               </section>
               <section>
                  <h3>PRODUCE-PROJECTS-ELEMENTLIST.xpl</h3>
                  <p>The pipeline <a href="../../PRODUCE-PROJECTS-ELEMENTLIST.xpl">PRODUCE-PROJECTS-ELEMENTLIST.xpl</a> has
                  <q>real-world complexity</q>. Reviewing its steps can give a sense of how XProc combines simple
               capabilities into complex operations. Notwithstanding the title of this section, it is not important to
               understand every detail – knowing they are there is enough.</p>
                  <ul>
                     <li>The prologue here contains a single <code>p:input</code> configuration. This one gives the input in
                  line, as an XML document. Within this XML, all the project folders to be covered by the index are
                  listed. Their order also matters since one of the two indexes built works incrementally, prior
                  elements affecting what happens with later elements.</li>
                  </ul>
                  <p>This pipeline exploits one other important feature of XProc: so far at least, it is all XML. Even short
               of of dynamically generating and executing XProc (a feature the language  <a href="https://spec.xproc.org/lastcall-2024-08/head/run/">provides for</a>), the common ground of XML
               format means that with XProc working XML tools, XML and its related ecosystem (most significantly but not
               only XPath) is always available as an instrumental force magnifier or power tool, something we can put to
               work again and again. In XProc, errors are reported in XML. So we can capture, aggregate and index error
               messages in XProc. In XProc, a directory file listing is provided in XML. So we have a ready way to
               present views of file systems – the XML shows all the names and structures – as well as analyze them and
               access the files in them. Etc.</p>
               </section>
            </section>
            <section>
               <h2>Messing around</h2>
               <p>Taking some time to make and test small adjustments to working code is a great way to develop a sense of how
            it behaves.</p>
               <p>An easy way to do this without perturbing the working code in the repository is to copy a pipeline and
            modify the copy. Modifying any of the pipelines presented so far, see what happens when:</p>
               <ul>
                  <li>An <code>@href</code> points to a location on the system where there is no file</li>
                  <li>A file is there, but it is not what is expected (for example: XML is expected but the file is not well
               formed)</li>
                  <li>A <code>p:namespace-delete</code> step is removed from the end of a pipeline – how does the result
               change?</li>
                  <li>Other steps are excluded</li>
                  <li>New elements are renamed (etc.)</li>
               </ul>
               <p>When changes introduce errors, runtime failures and tracebacks will <i>sometimes</i> appear. The indicated
            problem or the source of the reported problem must be repaired.</p>
               <p>And sometimes a process will run successfully, despite an <q>error</q>. Whether it is in error then depends
            on how well it conforms to its requirements. Does it deliver the results we want and expect?</p>
               <p>As an exercise, make some changes in copies of the test pipelines. Make at least one change that produces
            outputs (such as echoing a document to the console) that are visibly different from the results of the
            original pipeline.</p>
               <section>
                  <h3>Disabling your code</h3>
                  <p>For newcomers to XML coding – you can <q>comment out</q> code in any XML by wrapping it in comment
               syntax:</p>
                  <pre>&lt;tagged&gt;Text&lt;/tagged&gt;</pre>
                  <p>becomes</p>
                  <pre>&lt;!--  &lt;tagged&gt;Text&lt;/tagged&gt; --&gt;</pre>
                  <p>A code editor that supports XML might let you do this with a keystroke, for example <code>ctrl-,</code>
               (Control key plus comma), after selecting the text you wish to include in the comment.</p>
                  <p>Take care when doing this that the XML is still intact with all the tags balanced. This is a very useful
               technique for rapidly and interactively testing your pipelines, by deactivating and reactivating blocks
               of code.</p>
               </section>
            </section>
            <section>
               <h2>Take note</h2>
               <section>
                  <h3>Where are these downloads coming from?</h3>
                  <p>Pipelines can use a few different strategies for resource acquisition, depending on the case, and on
               where and in what form the resource is available. (Sometimes a file on Github is easiest to download
               "raw", sometimes an archive is downloaded and opened, and so on.) For now, it is not necessary to
               understand details in every case, only to observe the variation and range. (With more ideas welcome.
               Could XProc be used to build a <q>secure downloader</q> that knows how, for example, to compare
               hashes?)</p>
                  <p>Wherever you see <code>href</code> attributes, take note.</p>
                  <p>Since <code>href</code> is how XProc <q>sees</q> the world, either to read data in or to write data out,
               this attribute is a reliable indicator of an assumed feature, often a dependency of some kind. For
               example, a download will not succeed if the resource indicated by the <code>href</code> for the download
               returns an error, or nothing. In XProc, <code>href</code> attribute settings are the <i>points of
                  control</i> for interaction between an XProc pipeline, and its runtime environment.</p>
                  <p>Useful detail: where XProc has <code>p:store href="some-uri.file"</code>, the <code>href</code> is read
               by the processor as the intended location for storage of pipeline data, that is, for a <i>write</i>
               operation. In other cases <code>href</code> is always an argument for a <i>read</i> operation.</p>
               </section>
               <section>
                  <h3>Syntax tips</h3>
                  <p>In XPath syntax, <code>$foo</code> (a name with a <code>$</code> prefixed) indicates a <b>variable
                  reference</b> named (in this case) <q>foo</q>. XProc also uses a <i>value expansion syntax</i>
                  (either<i>text value syntax</i> or <i>attribute value syntax</i>) using curly braces - so syntax such
               as <code>href="{$some-xml-uri}"</code> is not uncommon. Depending on use, this would mean <q>read [or
                  write] to the URI given by <code>$some-xml-uri</code>
                     </q>.</p>
                  <p>An XProc developer always knows where <code>href</code> is used in a pipeline, and how to test for and
               update its use. As always with syntax, the easiest way to learn it is to try making changes and observing
               outcomes.</p>
               </section>
            </section>
         </section>
         <section class="unit learner"
                  id="walkthrough_399"
                  data-track="learner">
            <h1>399: XProc, XML and XDM  (the XML Data Model)</h1>
            <p>More in depth.</p>
            <section>
               <h2>Goals</h2>
               <ul>
                  <li>Consider XProc in its operational context including available <b>standards</b> and applicable
                  <b>requirements</b>, both generalized and local</li>
                  <li>Consider the context of XProc by learning or relearning some deep XML history</li>
                  <li>Inform your capability to assess the utility and appropriateness of XProc in particular and XML in
               general, for a given problem or domain</li>
               </ul>
            </section>
            <section>
               <h2>Resources</h2>
               <p>The same pipelines you ran in setup: <a href="../acquire/acquire_101_src.html"
                     class="LessonUnit">Setup
            101</a>.</p>
               <p>Also, <a href="https://xproc.org">XProc.org dashboard page</a>
               </p>
               <p>Also, XProc index materials produced in this repository: <a href="../../../projects/xproc-doc/readme.md">XProc docs</a>
               </p>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>Coverage here provides background information; there are no prerequisites. Prior exercises, or the practical
            equivalent, are assumed.</p>
            </section>
            <section>
               <h2>XProc as XML</h2>
               <p>XProc is defined as an XML vocabulary. A schema for the XProc language, considered as core steps (compound
            and atomic) plus optional community-defined steps, is referenced from the <a href="https://spec.xproc.org/3.0/xproc/#ancillary-files">XProc Specification</a>. <a href="https://spec.xproc.org/3.0/xproc/xproc30.rng">This RNG schema</a> is very useful.</p>
               <p>It may often be considered gratuitous to validate XProc files against a schema, when the application (for
            us, Morgana) must in any case take responsibility for conformance issues, as it sees fit. The reference
            schema becomes useful if we find or suspect bugs in Morgana, but until then it need not have any direct role
            in any runtime operation.</p>
               <p>Nevertheless, since XProc is XML, its schema still serves as a reference and an object for querying –
            queries whose results tell us about XProc. <a href="../../GRAB-XPROC-RESOURCES.xpl">A pipeline</a> for
            acquiring both the RNG schema and its RNC (compact syntax) variant is provided for interest and possible
            later use.</p>
               <section>
                  <h3>Survey of XProc elements</h3>
                  <p>All elements defined by XProc (at time of writing) are listed in this analytical breakout.</p>
                  <p>
                     <i>However</i>, this list is provisional and intended only to offer a wider view. For the most up to date
               information, refer to specifications. In particular, XProc 3.1 makes this list a moving target. This may
               be out of date by the time you are able to read it.</p>
                  <p> NB also – see Erik Siegel's <a href="https://xprocref.org/index.html">XProcRef</a> indexing project for
               more detailed summaries.</p>
                  <table>
                     <tbody>
                        <tr>
                           <th>Function</th>
                           <th>XProc elements / p: namespace</th>
                        </tr>
                        <tr>
                           <td>Documentation</td>
                           <td>
                              <code>p:documentation</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Top-level</td>
                           <td>
                              <code>p:declare-step</code>, <code>p:library</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Imports</td>
                           <td>
                              <code>p:import</code>, <code>p:import-functions</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Prologue</td>
                           <td>
                              <code>p:input</code>, <code>p:output</code>, <code>p:option</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Compound steps</td>
                           <td>
                              <code>p:group</code>, <code>p:for-each</code>, <code>p:viewport</code>, <code>p:if</code>,
                        <code>p:choose</code> (with <code>p:when</code> and <code>p:otherwise</code>),
                        <code>p:try</code> (with <code>p:catch</code> and <code>p:finally)</code>, <code>p:run</code>
                     (with <code>p:run-input</code>, <code>p:run-option</code>)</td>
                        </tr>
                        <tr>
                           <td>Atomic steps - core - XML</td>
                           <td>
                              <code>p:add-attribute</code>, <code>p:add-xml-base</code>, <code>p:delete</code>,
                        <code>p:filter</code>, <code>p:identity</code>, <code>p:insert</code>,
                        <code>p:label-elements</code>, <code>p:make-absolute-uris</code>,
                        <code>p:namespace-delete</code>, <code>p:namespace-rename</code>, <code>p:pack</code>,
                        <code>p:rename</code>, <code>p:replace</code>, <code>p:set-attributes</code>,
                        <code>p:uuid</code>, <code>p:unwrap</code>, <code>p:wrap-sequence</code>, <code>p:wrap</code>,
                        <code>p:xinclude</code>, <code>p:xquery</code>, <code>p:xslt</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Atomic steps - core - zipping</td>
                           <td>
                              <code>p:archive</code>, <code>p:archive-manifest</code>, <code>p:unarchive</code>,
                        <code>p:uncompress</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Atomic steps - core - JSON</td>
                           <td>
                              <code>p:json-join</code>, <code>p:json-merge</code>, <code>p:set-properties</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Atomic steps - core - plain text</td>
                           <td>
                              <code>p:string-replace</code>, <code>p:text-count</code>, <code>p:text-head</code>,
                        <code>p:text-join</code>, <code>p:text-replace</code>, <code>p:text-sort</code>,
                        <code>p:text-tail</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Atomic steps - core - utility</td>
                           <td>
                              <code>p:cast-content-type</code>, <code>p:compare</code>, <code>p:compress</code>,
                        <code>p:count</code>, <code>p:error</code>, <code>p:hash</code>, <code>p:http-request</code>,
                        <code>p:load</code>, <code>p:sink</code>, <code>p:split-sequence</code>, <code>p:store</code>,
                        <code>p:www-form-urldecode</code>, <code>p:www-form-urlencode</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Atomic steps - optional - file system</td>
                           <td>
                              <code>p:directory-list</code>, <code>p:file-copy</code>, <code>p:file-delete</code>,
                        <code>p:file-info</code>, <code>p:file-mkdir</code>, <code>p:file-move</code>,
                        <code>p:file-create-tempfile</code>, <code>p:file-touch</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Atomic steps - optional - validation</td>
                           <td>
                              <code>p:validate-with-nvdl</code>, <code>p:validate-with-relax-ng</code>,
                        <code>p:validate-with-schematron</code>, <code>p:validate-with-xml-schema</code>,
                        <code>p:validate-with-json-schema</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Other optional steps</td>
                           <td>
                              <code>p:os-info</code>, <code>p:os-exec</code>, <code>p:css-formatter</code>,
                        <code>p:xsl-formatter</code>, <code>p:markdown-to-html</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Variable declaration</td>
                           <td>
                              <code>p:variable</code>
                           </td>
                        </tr>
                        <tr>
                           <td>Connectors</td>
                           <td>
                              <code>p:with-input</code>, <code>p:with-option</code>, <code>p:pipe</code>,
                        <code>p:pipeinfo</code>, <code>p:document</code>, <code>p:inline</code>,
                     <code>p:empty</code>
                           </td>
                        </tr>
                     </tbody>
                  </table>
               </section>
            </section>
            <section>
               <h2>XML and the XDM: context and rationale</h2>
               <p>The technologies we rely on share a common foundation in XML and XDM (the XML data model), technologies
            developed under the auspices of the World Wide Web Consortium (W3C). For stability over a long term (years
            and decades rather than months), we require solutions that are:</p>
               <ul>
                  <li>Standard, non-proprietary and freely available without restriction</li>
                  <li>Consistently and repeatedly shown to be capable at scale (size/complexity)</li>
                  <li>Supported by commodity tools, easing problem of proprietary product dependencies</li>
               </ul>
               <p>Importantly, we need tools that are freely available to use without restriction, an important qualification
            for this distribution, which has a prior commitment <i>not to endorse particular technological solutions to
               any problem</i>, however posed or circumscribed. Accordingly, solutions here are not offered as
            recommendations, but rather as stipulations of (minimum) viable functionality in tools or capabilities, and
            not only using tools as <q>black boxes</q>, but under control and conformant to external specifications –
            i.e., standards.</p>
               <p>Users should keep in mind the model whereby we imagine the viability of a tools market and ecosystem that
            enables both large and small software developers – including independent developers, academic researchers,
            and students – to participate meaningfully, finding an appropriate value or service proposition to support
            immediate and long-term goals. Translated, this means the tools must be capable enough for industrial use at
            scale, while they must also <q>scale down</q> to demonstration or classroom use.</p>
               <p>In web standards including HTML and Javascript (ECMAScript) we arguably have the beginnings of such an
            ecosystem, while it is also contested and turbulent. Within the publishing sector more broadly and
            intersecting with the web, the XML family of standards arguably provides the best demonstration of complete
            or near-complete capabilities at least with respect to the harder problems of document processing.</p>
               <ul>
                  <li>XSLT up to <a href="https://www.w3.org/TR/xslt-30/">XSLT 3.0</a> (in <a href="https://www.saxonica.com/welcome/welcome.xml">Saxon</a>)</li>
                  <li>
                     <a href="https://www.w3.org/TR/xquery-31/">XQuery</a> (in Saxon)</li>
                  <li>
                     <a href="https://github.com/Schematron">Schematron</a> (in <a href="https://github.com/schxslt/schxslt">SchXSLT</a>, an open-source implementation in XSLT of <a href="https://schematron.com/">Schematron</a> including the <a href="https://www.iso.org/obp/ui/#iso:std:iso-iec:19757:-3:ed-3:v1:en">ISO/IEC 19757-3</a>
               specification</li>
                  <li>
                     <a href="https://github.com/xspec/xspec">XSpec</a>, a community-maintained XSLT-based framework for
               test-driven development, supporting testing XSLT, XQuery and Schematron</li>
               </ul>
               <p>Since they are known to be highly conformant to their respective specifications as well as well tested,
            these tools provide a useful functional baseline for evaluating other tooling that addresses the same
            functional requirements.</p>
               <p>They are also, relatively speaking, <i>mature</i> technologies, at least in comparison to similar
            offerings.</p>
               <p>And when XProc works, we also have the functional underpinnings we need for comparing - for example -
            different XSLT implementations.</p>
               <p>Initiated in 1996, XML continues to be generative in 2024.</p>
            </section>
            <section>
               <h2>Snapshot history: an XML time line</h2>
               <p>[TODO: complete this, or move it, or both]</p>
               <table>
                  <thead>
                     <tr>
                        <th>Year</th>
                        <th>Publication</th>
                        <th>Capabilities</th>
                        <th>Processing frameworks</th>
                        <th>Platforms</th>
                     </tr>
                  </thead>
                  <tbody>
                     <tr>
                        <td>1987</td>
                        <td>SGML (ISO-IEC 8879-1)</td>
                        <td>parsing logic; schema validation; configurable syntax; (implicit) tree of elements and
                     attributes</td>
                        <td>Proprietary stacks</td>
                        <td>Mainframes, workstations</td>
                     </tr>
                     <tr>
                        <td>1996</td>
                        <td>Unicode 2.0</td>
                        <td>standard character sets</td>
                        <td>… support for Unicode is slow to come</td>
                        <td>PCs</td>
                     </tr>
                     <tr>
                        <td>1998</td>
                        <td>XML 1.0</td>
                        <td>standard syntax</td>
                        <td>Batch processing, shell scripts, <code>make</code>
                        </td>
                        <td>Mainframes, workstations, PCs (x86 generation), *nix, shell, sed/awk, Perl</td>
                     </tr>
                     <tr>
                        <td>1999</td>
                        <td>XPath 1.0, XSLT 1.0</td>
                        <td>basic tree querying and transformations (<q>down hill</q>); functional support for namespaces</td>
                        <td>Web browsers? (some, sort of); standalone XSLT processors</td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>2000</td>
                        <td>
                        </td>
                        <td>XML-configured software builds</td>
                        <td>Apache Ant</td>
                        <td>Java</td>
                     </tr>
                     <tr>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>Perl, Python</td>
                     </tr>
                     <tr>
                        <td>
                        </td>
                        <td>XQuery 1.0</td>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>
                        </td>
                        <td>XPath 2.0</td>
                        <td>
                        </td>
                        <td>Server frameworks (Apache Cocoon)</td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>2001</td>
                        <td>XML Schema Definition language (XDM)</td>
                        <td>Standardizes atomic data types (foundations of XSD); namespace-based validation (RNG also offers
                     this, 2001-2002)</td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>2003</td>
                        <td>
                        </td>
                        <td>Pipelining as a build process</td>
                        <td>Apache Ant</td>
                        <td>Java</td>
                     </tr>
                     <tr>
                        <td>2003-2004</td>
                        <td>W3C Document Object Model (DOM)</td>
                        <td>API for HTML and XML documents</td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>2005</td>
                        <td>
                           <q>The XML data model</q> (W3C)</td>
                        <td>An essay</td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>2006</td>
                        <td>XProc 1.0 Requirements</td>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>Proof-of-concept demonstrations</td>
                     </tr>
                     <tr>
                        <td>2007</td>
                        <td>XSLT 2.0</td>
                        <td>Transformations (<q>up hill</q>) including grouping, string processing, pipelining</td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>
                        </td>
                        <td>XDM (XPath/XQuery data model)</td>
                        <td>Unifying a data model for XPath, XSLT and XQuery</td>
                        <td>
                        </td>
                        <td>Client- and server-side XML processing stacks</td>
                     </tr>
                     <tr>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>XQuery+XSLT in eXist-db or BaseX (XQuery engines)</td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>
                        </td>
                        <td>XPath 3.0</td>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>
                        </td>
                        <td>XPath 3.1</td>
                        <td>Higher-order functions, map and array objects</td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>2010</td>
                        <td>XProc 1.0</td>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>2017</td>
                        <td>XSLT 3.0/3.1</td>
                        <td>JSON harmonization, functions as arguments</td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>
                        </td>
                        <td>XProc 3.0</td>
                        <td>Easier syntax, plus adding support for JSON and other content types</td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                     <tr>
                        <td>2022</td>
                        <td>Unicode 15.0</td>
                        <td>
                        </td>
                        <td>
                        </td>
                        <td>
                        </td>
                     </tr>
                  </tbody>
               </table>
               <p>The technologies have been in constant use over this period.</p>
               <p>Historically, the requirements of processing frameworks have often been met by software developers' build
            utilities (for example, GNU <code>make</code> or Apache Ant). This is not an accident: in certain respects,
            a publishing framework can be considered as a <q>documentary build</q>, to be run at intervals corresponding to the publishing cycle with its proof runs.</p>
            </section>
            <section>
               <h2>XPath</h2>
               <p>Like other XDM-based technologies, XProc embeds and incorporates XPath, an expression language for XML.
            XPath 3.0 is a functional language in its own right, although not designed for end-to-end processing of
            encoded source data into encoded results, but only for certain critical operations that ordinarily need to
            be performed within such end-to-end processing. Importantly, XPath is defined not in terms of any data
            notation (such as XML syntax or any other) but rather against an <i>abstract data object</i>, namely an <a href="https://www.w3.org/TR/xpath-datamodel/">XDM</a> instance (XML data model), a putative information
            object that may be provided to the system by parsing an XML (syntax) instance, or by other means. As the
            query language for <a href="https://www.w3.org/TR/xpath-datamodel/">XDM</a> and the basis for XQuery, <a href="https://www.w3.org/TR/xpath-31/">XPath</a> is the <q>other half</q> of the data model, which any
            architect of a system using this technology must know. Learning XPath equips you mentally for dealing with
            the XDM in XQuery, XSLT, XProc or anywhere you find it.</p>
               <p>For those not already familiar with XPath, on line resources can be helpful. Keep in mind that <a href="https://www.w3.org/TR/xpath-31/">XPath 3.1</a> outstrips earlier versions of the language in many
            important respects (supporting map and function objects with higher-order functions, among other
            features).</p>
               <section>
                  <h3>Documents and data</h3>
                  <p>One of the more important features of XPath and the XDM is that they are designed not only to meet needs
               for the representation and transmission of structured data. A specialized class of data formats has
               evolved that represent information in ways that are not <q>unstructured</q>, but that contrast with more
               common or usual structures of data formats, whether they be tabular data, serialization formats for
               object models, or some other regular (formalized and codified) arrangement for purposes of
               machine-readability. One might say <q>common</q> or <q>usual</q> with reservation, since of course
               documents are not uncommon where they are common. The prevalence of so-called structured data in digital
               systems may tell us more about the limits of those systems than it does about information in general.</p>
                  <p>We see a great deal of structured data these days if only because it is so easy to make structured data
               with machines, and we now have the machines. What remains difficult is to translate what has not been
               created by a machine, into a form that a machine can <q>recognize</q>, or rather into a form we can
               recognize in and with the machine, without mishandling it and distorting it. Since machines do not
               recognize anything (nothing is <q>mishandling</q> to them), what this often reduces to in practice is
               deciding how to agree on a <b>representation</b> for information that any creator and any consumer can
               recognize and work with, without seeing the information first. In itself this is a formidable
               challenge.</p>
                  <p>So documents are called <q>unstructured</q> but they might better be called <q>relatively irregular</q>,
               meaning not that they have no structure, but that each one is structured in itself, and moreover, likely
               to be incompatible or not fully compatible with encodings designed to capture other structures.</p>
                  <p>And to the extent this is the case, any encoding capable of describing documents must have the capability
               of supporting each document's own distinctive structure and organization, whether that be due to its
               family (what is called a <b>document type</b>) or an expression of its own intrinsic logic. The format
               must be not only structured, but <i>structurable</i>, and its structures must to some extent be capable
               of self-description – combining data with metadata.</p>
                  <p>And this is to give no consideration to the fact that these structures can be described at <i>multiple
                  levels</i> of generality or specificity with regard to either their supposed semantics, or their
               configuration in operation.</p>
                  <p>Documentary data formats especially markup formats are designed to work in this in-between space.</p>
                  <p>And so we get XPath - a query syntax which permits working with an organized structure of a particular
               kind (an <i>XDM document tree</i>), which in turn is designed for handling the combination of <i>highly
                  regular</i> and <i>quite irregular</i> data structures that characterize information sets we (loosely)
               call <b>documentary</b>.</p>
                  <p>A definition for what is a document is out of scope for this tutorial – an interesting topic but not only
               a technical one.</p>
               </section>
               <section>
                  <h3>XPath illustrative examples</h3>
                  <p>This is not the place to learn XPath, but a selection of XPath expressions can offer a hint of its
               capabilities.</p>
                  <table>
                     <thead>
                        <tr>
                           <th>XPath</th>
                           <th>Returns</th>
                           <th>XPath long (explicit) notation</th>
                        </tr>
                     </thead>
                     <tbody>
                        <tr>
                           <td>
                              <code>/html</code>
                           </td>
                           <td>An XML document root (top-level) element named <code>html</code> (subject to namespace
                        resolution)</td>
                           <td>
                              <code>/child::html</code>
                           </td>
                        </tr>
                        <tr>
                           <td>
                              <code>//p</code>
                           </td>
                           <td>All the elements named <code>p</code> in the document</td>
                           <td>
                              <code>/descendant-or-self::element()/ child::p</code>
                           </td>
                        </tr>
                        <tr>
                           <td>
                              <code>//seg[@type='null']</code>
                           </td>
                           <td>All the elements named <code>seg</code> with an attribute <code>type</code> with value
                           <code>null</code>
                           </td>
                           <td>
                              <code>/descendant-or-self::element()/ child::seg[attribute::type='null']</code>
                           </td>
                        </tr>
                        <tr>
                           <td>
                              <code>/*</code>
                           </td>
                           <td>Any document (rather, any element at the top of a document) - <code>*</code> is a wildcard
                        character</td>
                           <td>
                              <code>/child::element()</code>
                           </td>
                        </tr>
                        <tr>
                           <td>
                              <code>/section[exists(.//table)]</code>
                           </td>
                           <td>An element inside the top-level element, named <code>section</code>, that contains a
                           <code>table</code> element anywhere inside it</td>
                           <td>
                              <code>/child::section[exists(self::node()/ descendant-or-self::element()/ child::table)]</code>
                           </td>
                        </tr>
                        <tr>
                           <td>
                              <code>/descendant::p[10]</code>
                           </td>
                           <td>The tenth <code>p</code> element in the document</td>
                           <td>
                              <code>/descendant::p[position() eq 10]</code>
                           </td>
                        </tr>
                        <tr>
                           <td>
                              <code>//p[10]</code>
                           </td>
                           <td>All <code>p</code> elements, that are the tenth <code>p</code> inside their respective
                        parents</td>
                           <td>
                              <code>/descendant-or-self::element()/ child::p[position() eq 10]</code>
                           </td>
                        </tr>
                        <tr>
                           <td>
                              <code>//section[count(.//p) gt 10]</code>
                           </td>
                           <td>All <code>section</code> elements that contain more than 10 <code>p</code> elements, at any
                        depth</td>
                           <td>
                              <code>/child::section[count(self::node()/ descendant-or-self::element()/ child::p) gt
                        10]</code>
                           </td>
                        </tr>
                     </tbody>
                  </table>
                  <p>Where do you find XPath? Any <code>select</code> or <code>match</code> expression in XSLT or XProc shows
               an example. XPath also constitutes the core of XQuery.</p>
               </section>
            </section>
            <section>
               <h2>Exercise: Discussion board</h2>
               <p>Create or contribute to a Github discussion board offering perspective or (especially!) relevant information
            or experience on any of the larger questions.</p>
            </section>
         </section>
         <section class="unit learner"
                  id="walkthrough_401"
                  data-track="learner">
            <h1>401 - XSLT Forward and Back</h1>
            <p>What is this XSLT?</p>
            <p>Read this page if you are a beginner, or an expert in XSLT, or if you plan never to use it.</p>
            <section>
               <h2>Goals</h2>
               <ul>
                  <li>If you don't know XSLT, helps you understand what it is and what it does</li>
                  <li>If you know XSLT, understand something more about how it fits with XProc</li>
               </ul>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>You have run and inspected pipelines mentioned earlier, most especially <a href="../../PRODUCE-PROJECTS-ELEMENTLIST.xpl">PRODUCE-PROJECTS-ELEMENTLIST.xpl</a>, which contains
               <code>p:xslt</code> steps.</p>
               <p>You have inspected XSLT files (standalone transformations or <em>stylesheets</em>), to be found more or less
            anywhere in this repository, especially directories named <code>src</code>.</p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>XSLT links!</p>
               <section>
                  <h3>XSLT 1.0 and XPath 1.0</h3>
               </section>
               <section>
                  <h3>XSLT 2.0 and XQuery 1.0</h3>
               </section>
               <section>
                  <h3>XSLT 3.0, XQuery 3.0, XPath 3.1</h3>
               </section>
            </section>
            <section>
               <h2>XSLT: XSL (XML Stylesheet Language) Transformations</h2>
               <p>XSLT has a long and checkered reputation and a history that may be even more amazing.</p>
               <p>Chances are good that if you are not current on the latest version of this technology, you have little idea
            of what we are talking about, as it may have changed quite a bit (and even despite external appearances)
            since you last saw it.</p>
               <p>Users who last used XSLT 1.0 and even 2.0, in particular, can consider their knowledge out of date until
            they have taken a look at XSLT 3.0.</p>
               <p>Programmers can think of XSLT as a domain-specific language (DSL) or fourth-generation language (4GL)
            designed for the purpose of manipulating data structures suitable for documents and messages as well as for
            structured data sets. As such, XSLT is highly generalized and abstract and can be applied to a very broad
            range of problems. Its main distinguishing feature among similar languages (which tend to be functional
            languages such as Scala and Scheme) is that it is optimized for use specifically with XML-based data
            formats, offering well-defined handling of information sets expressed in XML, while the language itself uses
            XML syntax, affording nice composability, reflection and code generation capabilities. XSLT's processing
            model is both broadly applicable, and workable in a range of environments including client software or
            within encapsulated, secure software configurations and deployments.</p>
               <p>If your XSLT is strong enough, you don't need XProc, or not much. But as a functional language, XSLT is best
            used in a functionally pure, <q>stateless</q> way that does not interact with the system: no <q>side
               effects</q>. This is related to its definitions of conformant processing (X inputs produce Y outputs) and
            the determinism, based in mathematical formalisms, that underlies its idea of conformance. However one cost
            of mathematical purity is that operations that do interact with stateful externalities – things such as
            reading and writing files – are not in XSLT's <q>comfort zone</q>. It easily defines what a new structure A'
            should look like for any given structure A. But how A is first acquired or what we do once we have
            determined A', is less clear, and left up to the processor to handle, as an interface, starting with an XSLT
            transformation's nominal <em>source</em> and (primary) <em>result</em>. Often, this gap has been bridged by
            extended functionality in processors. Does your processor read and parse XML files off the file system? Can
            it be connected to upstream data producers in different ways? Can it use HTTP <code>GET</code> and
               <code>PUT</code>? The answer may be Yes to any or all of these. Throughout its history, XSLT in later
            versions was also extended in this direction, with features such as the <code>collection()</code> function,
               <code>xsl:result-document</code>, <code>doc-available()</code> and other features we may not need if we
            are using XProc.</p>
               <p>XSLT is commonly run from scripts, in web hosting environments and XQuery databases. Or you might be able to
            configure your desktop software (Editor or IDE) to run your XSLT, or acquire specialized software just for
            reading and filtering collections or managing sets of file outputs in XSLT-based workflows.</p>
               <p>Yet XProc may offer a gentler approach, while it enables XSLT on the one hand when needed, while on the
            other enables us largely to do without it, offering both a useful feature set and the flexibility we need,
            but with less overhead, especially with regard to routine chores like designating sets of inputs and
            outputs, or sequencing operations. The principle of Least Power may well apply here: it saves our present
            and our future selves effort if we can arrange and manage to do things less. XProc lets us do less.</p>
               <p>XProc lets us use XSLT when we must, but also keeps routine and simple things both simple and consistent.
            And it adapts itself well to new requirements as they become more complicated. Ultimately, it spares the
            XSLT developer the problem of having to design, build and test something like XProc.</p>
               <section>
                  <h3>Running XSLT without XProc</h3>
                  <p>As a standard and an externally-specified technology, XSLT can in principle be implemented on any
               platform, but the leading XSLT implementation for some years has been Saxon, produced by Saxonica of
               Reading, England. Saxon has achieved market share and developer support on a record of
               strictly-conformant, performant applications, deployed as an open-source software product free for
               developers to use and integrate. (While doing this, Saxonica also has related product offerings including
               optimized processor for those who choose to support it.)</p>
                  <p>Download and run Saxon to apply XSLT to XML and other inputs, without XProc.</p>
               </section>
            </section>
            <section>
               <h2>Using XSLT in XProc: avoiding annoyances XXX</h2>
               <p>If you are an experienced XSLT user, congratulations! The power XProc puts into your hands is everything you
            might think and hope.</p>
               <p>There are a couple of small but potentially annoying considerations when embedding XSLT literals in your
            XProc code. They do not apply when your XSLT is called from out of line, acquired by binding to an input
            port or even <code>p:load</code>. If you acquire and even manipulate your XSLT without including literal
            XSLT code in your XProc, that eliminates the syntax-level clashes at the roots of both these problems.</p>
               <section>
                  <h3>Text and attribute value syntax in embedded XSLT</h3>
               </section>
               <section>
                  <h3>Namespaces in and for your XSLT</h3>
               </section>
            </section>
            <section>
               <h2>Learning XSLT the safer way</h2>
               <p>If setting out to learn XSLT, pause to read the following list of things to which you should give early
            attention, in order:</p>
               <ol>
                  <li>Namespaces in XML and XSLT: names, name prefixes, unprefixed names and the
                  <code>xpath-default-namespace</code> setting (not available until XSLT 2.0)</li>
                  <li>Templates and modes in XSLT: template matching, <code>xsl:apply-templates</code>, built-in templates,
               and using modes to configure default behaviors when no template matches</li>
                  <li>XPath, especially absolute and relative location paths: start easy and work up</li>
               </ol>
               <p>Only one of these topics does not also apply to XProc.</p>
            </section>
            <section>
               <h2>XProc without XSLT?</h2>
               <p>XProc does not require XSLT absolutely, even if XSLT is indispensable for some of XProc libraries, including
            those in this repository.</p>
               <p>How could we do without it?</p>
               <ul>
                  <li>Using XQuery any time queries get complicated</li>
                  <li>Use XProc where possible, for example steps that support matches on patterns? E.g.
               <code>p:insert</code>, <code>p:label-elements</code> and <code>p:add-attribute</code>
                  </li>
                  <li>Reliance on iterators and <code>p:viewport</code>
                  </li>
                  <li>Much smarter (declarative, data-centric) HTML or other dialect in the application space?</li>
               </ul>
               <p>Chances are, there is a limit. One thing XSLT does better than almost any comparable technology is support
            generalized or granular mappings between vocabularies.</p>
               <p>So not only creating, but also consuming HTML, is the place we begin with XSLT. But since it is also very
            fine for other vocabulary mappings in the middle and back, it becomes indispensable almost as soon as it is
            available for use.</p>
            </section>
            <section>
               <h2>XProc, XDM (the XML data model) and the standards stack</h2>
               <p>Another critical consideration is whether and to what extent XProc and XSLT introduce unwanted dependencies,
            which make them strategically not a good choice (or not a good choice for everyone) at least in comparison
            to alternatives. These are standards in every way including nominally - emerging as the work of
            organizations such as W3C and ISO, while not escaping a reputation as <q>boutique</q> or <q>niche</q>
            technologies. Yet alternative models – whether to go with the big guys, or rely on forests of Javascript
            libraries, or support a bespoke Markdown-based stack – have not all fared very well either. Often scorned,
            XSLT has a reputation for projects migrating away from it as much as towards it. Yet look closely, and when
            problems arise, XSLT is never the issue by itself. Often the question is, were you even using the right
            tool? one way is to be in the sweet spot (and there is a sweet spot) of document processing at scale, but
            this is not definitive. Sometimes the question is, are you actually fitting the capabilities of the
            processing model to the problem at hand. Too often, that fit happens by accident.</p>
               <p>So where has XML-based processing been not only tenable but rewarding over the long term? Interestingly, its
            success is to be found often in projects that have survived across more than one system over time, that have
            grown from one system into another, and that have morphed and adapted and grown new limbs. (Pubmed Central
            comes to mind. But what about Optical Society? PLOS?) In other words, look at them today and you do not see
            the same system as you would have only five years ago.</p>
            </section>
         </section>
      </section>
      <section class="lesson"
               id="oscal-convert"
               name="oscal-convert">
         <section class="unit observer"
                  id="oscal-convert_101"
                  data-track="observer">
            <h1>101: OSCAL from XML to JSON and back</h1>
            <section>
               <h2>Goals</h2>
               <p>Learn how OSCAL data can be converted between JSON and XML formats, using XProc.</p>
               <p>Learn something about potential problems and limitations when doing this, and about how to detect, avoid,
            prevent or mitigate them.</p>
               <p>Become familiar with the idea of generic conversions between syntaxes such as XML and JSON (not always
            possible), versus conversions designed to handle a single class or type of documents, such as OSCAL format
            conversions.</p>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>You have succeeded in prior exercises, including tools installation and setup.</p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>This unit relies on the <a href="../../../projects/oscal-convert/readme.md">oscal-convert project</a> in
            this repository, with its files. Like all projects in the repo, it aims to be reasonably self-contained and
            self-explanatory. Use your search engine and XProc resources to learn background and terminology.</p>
               <p>Also like other projects, there are preliminaries for acquiring resources, along with pipelines to run.</p>
            </section>
            <section>
               <h2>Step zero: an identity pipeline</h2>
               <p>To verify syntactic correctness (well-formedness) - does it parse?</p>
               <p>To transcode a file from one encoding to another</p>
            </section>
            <section>
               <h2>Step zero-point-five: XML to JSON and back</h2>
               <p>XML and JSON are both <i>data serializations</i>, a term that designates how each of them is to be
            considered and treated – irrespective of any questions of information storage – as a <i>sequence of
               characters</i>. This is a very important commonality, which makes it possible to bring them together in a
            single processing environment such as XProc.</p>
               <p>Along with <i>plain text</i>, perhaps the most important data serialization or <q>format</q> as we call
            them, of the three.</p>
               <p>A simple XProc pipeline can be used to demonstrate this. While doing so, it shows also while this is not as
            simple a process as it seems. Merely to convert from format to format is not enough.</p>
            </section>
            <section>
               <h2>Step one: convert some OSCAL XML into OSCAL JSON</h2>
               <p>
                  <a href="../../../projects/oscal-convert/GRAB-RESOURCES.xpl">An acquisition pipeline</a> in the project
            folder collects some OSCAL onto the local system, where it can be managed, easily inspected, controlled, and
            edited if necessary.</p>
               <p>TBD / this all incoherent so far</p>
               <section>
                  <h3>The playing field is the internet</h3>
                  <p>Keep in mind that XProc in theory, and your XProc engine in practice, may read its inputs using whatever
               protocols it supports, while the <code>file</code> and <code>http</code> protocols are required for
               conformance, and work as they do on the Worldwide Web.</p>
                  <p>Of course, permissions must be in place to read files from system locations, or save files to them.</p>
                  <p>But when authentication is configured or resources are openly available, using <code>http</code> to reach
               resources or sources can be a very convenient option.</p>
               </section>
               <section>
                  <h3>Consider the options</h3>
                  <p>TBD - TODO - question - how many and of what sort of source data files - so far there is only the cat
               catalog</p>
                  <ul>
                     <li>Converting local XML to JSON with a local XSLT</li>
                     <li>Converting local data using a remote XSLT</li>
                     <li>Remote data with a local XSLT, writing locally - you could try <a href="https://github.com/GSA/fedramp-automation/blob/master/dist/content/rev5/baselines/xml/FedRAMP_rev5_LOW-baseline-resolved-profile_catalog.xml">https://github.com/GSA/fedramp-automation/blob/master/dist/content/rev5/baselines/xml/FedRAMP_rev5_LOW-baseline-resolved-profile_catalog.xml</a>
                     </li>
                  </ul>
               </section>
            </section>
            <section>
               <h2>Step two: return trip</h2>
               <p>Two ways: separate pipeline; and single pipeline; also a 'switcher' pipeline?</p>
            </section>
            <section>
               <h2>What is this XSLT?</h2>
               <p>If your criticism of XProc so far is that it makes it look easy when it isn't, you have a point.</p>
               <p>Conversion from XML to JSON isn't free, assuming it works at all.</p>
               <p>In this case, the heavy lifting is done by the XSLT component - the Saxon engine invoked by the
               <code>p:xslt</code> step, applying logic defined in an XSLT stylesheet (aka transformation) stored
            elsewhere. It happens that a converter for OSCAL data is available in XSLT, so rather than having to
            confront this considerable problem ourselves, we drop in the solution we have at hand.</p>
               <p>In later units we will see how using the XProc steps described, rudimentary data manipulations can be done
            using XProc by itself, without entailing the use of either XSLT or XQuery (another capability invoked with a
            different step).</p>
               <p>At the same time, while pipelines are based on the idea of passing data through a series of processes, there
            are many cases where logic is sufficiently complex that it becomes essential to maintain – and test – that
            logic externally from the XProc. At what point it becomes more efficient to encapsulate logic separately
            (whether by XSLT, XQuery or other means), depends very much on the case.</p>
               <p>The <code>p:xslt</code> pipeline step in particular is so important for real-world uses of XProc that it is
            introduced early, to show such a black-box application.</p>
               <p>XProc also makes a fine environment for testing XSLT developed or acquired to handle specific tasks, a topic
            covered in more depth later.</p>
               <p>Indeed XSLT and XQuery being, like XProc itself, declarative languages, it makes sense to factor them out
            while maintaining easy access and transparency for analysis and auditing purposes.</p>
            </section>
            <section>
               <h2>What could possibly go wrong?</h2>
               <p>When coping with errors, syntax errors are relatively easy. But anomalous inputs, especially invalid inputs,
            can result in lost data. (A common reason data is not valid even when it appears to be is that it has
            foreign unknown contents, or contents out of place - the kinds of things that might fail to be converted.)
            The most important concern when engineering a pipeline is to see to it that no data quality problems are
            introduced inadvertantly. While in comparison to syntax or configuration problems, data quality issues can
            be subtle, there is also good news: the very same tools we use to process inputs into outputs, can also be
            used to test and validate data to both applicable standards and local rules.</p>
               <p>Generally speaking, OSCAL maintains <q>validation parity</q> between its XML and JSON formats with respect
            to their schemas. That is to say, the XSD (XML schema) covers essentially the same set of rules for OSCAL
            XML data as the JSON Schema does for OSCAL JSON data, accounting for differences between the two notations,
            the data models and how information is mapped into them. A consequence of this is that valid OSCAL data,
            either XML or JSON, can reliably be converted to valid data in the other notation, while invalid data may
            not be converted at all, resulting in gaps or empty results.</p>
               <p>For this and related reasons on open systems, the working principle in XML is often to formalize a model
            (typically by writing and deploying a schema) as early as possible - or adopt a model already built - as a
            way to institute and enforce schema validation as a <b>prerequisite</b> and <b>primary requirement</b> for
            working with any data set. Validation against schemas is covered in a subsequent lesson unit (coming soon
            near you).</p>
               <section>
                  <h3>Intercepting errors</h3>
                  <p>One way to manage the problem of ensuring input quality is to validate on the way in, either as a
               dependent (prerequisite) process, or built into a pipeline. Whatever you want to do with invalid inputs,
               including ignoring them and producing warnings or runtime exceptions, can be defined in a pipeline much
               like anything else.</p>
                  <p>In the <a href="../../../projects/oscal-publish/publish-oscal-catalog.xpl">publishing demonstration
                  project folder</a> is an XProc that valides XML against an OSCAL schema, before formatting it. The
               same could be done for an XProc that converts the data into JSON - either or both before or after
               conversion.</p>
                  <p>Learn more about recognizing and dealing with errors in <a href="oscal-convert_102_src.html"
                        class="LessonUnit">Lesson 102</a>, or continue on to the next project, oscal-validate, for more on
               validation of documents and sets of documents.</p>
               </section>
            </section>
         </section>
         <section class="unit maker"
                  id="oscal-convert_102"
                  data-track="maker">
            <h1>102: Hands on data conversions</h1>
            <section>
               <h2>Goals</h2>
               <p>Learn how OSCAL data can be converted between JSON and XML formats, using XProc.</p>
               <p>Learn something about potential problems and limitations when doing this, and about how to detect, avoid,
            prevent or mitigate them.</p>
               <p>Work with XProc features designed for handling JSON data (XDM <b>map</b> objects that can be cast to
            XML).</p>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>Run the pipelines described in <a href="https://github.com/usnistgov/oscal-xproc3/discussions/18">the 101
               Lesson</a>
               </p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>Same as the <a href="oscal-convert_101_src.html"
                     class="LessonUnit">101 lesson</a>.</p>
            </section>
            <section>
               <h2>Some breaking and making</h2>
               <p>Every project you examine provides an opportunity to alter pipelines and see how they fail when not encoded
            correctly – when <q>broken</q>, any way we can think of breaking them. Then build good habits by repairing
            the damage. Experiment and observation bring learning.</p>
               <p>After reading this page and <a href="../../../projects/oscal-convert/readme.md">the project readme</a>, run
            the pipelines while performing some more disassembly / reassembly. Here are a few ideas (including a few you
            may have already done):</p>
               <ul>
                  <li>Switch out the value of an <code>@href</code> on a <code>p:document</code> or <code>p:load</code> step.
               See what happens when the file it points to is not actually there.</li>
                  <li>There is a difference between <code>p:input</code>, used to configure a pipeline in its prologue, and
                  <code>p:load</code>, a step that loads data. Ponder what these differences are. Try changing a
               pipeline that uses one into a pipeline that uses the other.</li>
                  <li>Similarly, there is a difference between a <code>p:output</code> configuration for a pipeline, and a
                  <code>p:store</code> step executed by that pipeline. Consider this difference and how we might define
               a rule for when to prefer one or the other. How is the pipeline used - is it called directly, or intended
               for use as a step in other pipelines? How is it to be controlled at runtime?</li>
                  <li>Try inserting <code>p:store</code> steps into a pipeline to capture intermediate results, that is, the
               output of any step before they are processed by the next step. Such steps can aid in debugging, among
               other uses.</li>
                  <li>
                     <code>@message</code> attributes on steps provide messages for the runtime traceback. They are optional
               but this repo follows a rule that any <code>p:load</code> or <code>p:store</code> should be provided with
               a message. Why?</li>
                  <li>A <code>p:identity</code> step passes its input unchanged to the next step. But can also be provided
               with a <code>@message</code>.</li>
               </ul>
               <p>After breaking anything, restore it to working order. Create modified copies of any pipelines for further
            analysis and discussion.</p>
               <ul>
                  <li>Concept: copy and change one of the pipelines provided to acquire a software library or resource of your
               choice.</li>
               </ul>
            </section>
            <section>
               <h2>Value templates in attributes and text: { expr }</h2>
            </section>
            <section>
               <h2>Designating an input at runtime by binding input ports</h2>
               <p>One potential problem with the pipelines we have looked at so far is that their inputs are hard-wired. While
            this is sometimes helpful, it should also be possible to apply a pipeline to an XML document (or other
            input) without having to designate the document inside the pipeline itself. The user or calling application
            should be able to say <q>run this pipeline, but this time with this input</q>.</p>
               <p>The input ports for a pipeline, specified using <code>p:input</code> within the prologue, provide for
            this.</p>
               <p>For example, the <a href="../../../projects/oscal-convert/CONVERT-OSCAL-XML-DATA.xpl">CONVERT-OSCAL-XML-DATA</a> pipeline defines an input port:</p>
               <pre>&lt;p:input port="source" sequence="true"&gt;
    &lt;p:document href="data/catalog-model/xml/cat_catalog.xml"/&gt;
&lt;/p:input&gt;</pre>
               <p>By default, this pipeline will pick up and process the data it finds at path
               <code>data/catalog-model/xml/cat_catalog.xml</code>, relative to the stylesheet. But any call to this
            pipeline, whether directly or as a step in another pipeline, can override this.</p>
               <p>The Morgana processor defines <a href="https://www.xml-project.com/manual/ch01.html#R_ch1_s1_2">a command
               syntax for binding inputs to ports</a>. It looks like this (when used with the script deployed with this
            repository):</p>
               <pre>$ ../xp3.sh <i>PIPELINE.xpl</i> -input:<i>portname=path/to/a-document.xml</i> -input:<i>portname=path/to/another-document.xml</i>
               </pre>
               <p>Here, two different <code>-input</code> arguments are given for the same port. You can have as many as
            needed if the port, like this one, has <code>sequence="true"</code>, meaning any number of documents (from
            zero to many) can be bound to the port, and the pipeline will accommodate. When more than one port is
            defined, one (only) can be designated as <code>primary="true"</code>, meaning it will be provided implicitly
            when a port connection is required (by a step) but not given in the pipeline. Notice that the name of the
            port must also appear, as in <code>-input:portname</code>, since pipelines can have ports supporting
            sequences, but also as many input ports as it needs, named differently, for documents playing different
            roles in the pipeline. In place of <code>portname</code> here, a common name for a port (conventional when
            it is the pipeline's only or primary input) is <code>source</code>.</p>
               <section>
                  <h3>Binding to input ports vs p:load steps</h3>
                  <p>XProc offers two ways to acquire data from outside the pipeline: by using <code>p:load</code> or by
               binding inputs to an input port using <code>p:input/p:document</code>. These are somewhat different in
               operation - errors produced by <code>p:load</code> cannot be detected until the pipeline is run, whereas
               failures with <code>p:input</code> should be detected when the pipeline itself is loaded and compiled
               (i.e. during <em>static analysis</em>), and processors may be able to apply different kinds of exception
               handling, fallbacks or support for redirects. (As always you can try, test and determine for yourself.)
               Apart from this distinction the two approaches have similar effects – whether to use one or the other
               depends often on how you expect the pipeline to be used and distributed, not on whether it works.</p>
                  <p>Although one distinction is that p:document appears on input ports, which can be overridden, this does
               not mean that p:document can't be essentially <q>private</q> to a pipeline or pipeline step. For example,
               if you wish to acquire more than a single document, without p:load, known in advance (i.e. the file names
               can be hard-coded), make a step like this:</p>
                  <pre>&lt;p:identity&gt;
  &lt;p:with-input&gt;
    &lt;p:document href="..."/&gt;
    &lt;p:document href="..."/&gt;
    ...
  &lt;/p:with-input&gt;
&lt;p:identity&gt;</pre>
                  <p>This binds the documents to the input of an <b>identity</b> step (which supports a sequence), without
               exposing an input port in the main pipeline.</p>
                  <p>A more dynamic approach is sometimes useful: first, acquire a list of file names, for example:</p>
                  <pre>&lt;p:input port="source"&gt;
   &lt;p:inline&gt;
      &lt;FILELIST&gt;
         &lt;FILE&gt;A&lt;/FILE&gt;
         &lt;FILE&gt;B&lt;/FILE&gt;
      &lt;/FILELIST&gt;
   &lt;/p:inline&gt;
&lt;/p:input&gt;</pre>
                  <p>Then in our subpipeline we use the compound step <code>p:for-each</code> to process each FILE element in
               the list:</p>
                  <pre>&lt;p:for-each&gt;
   &lt;p:with-input select="//FILE"/&gt;
   &lt;p:load href="{ string(.) }"/&gt;
&lt;/p:for-each&gt;   </pre>
                  <p>This has the effect of traversing the document given in line (the file list) and for each of its FILE
               elements, loading the document named as the FILE element's string value, that is <q>A</q>, <q>B</q> and
               so on. This is just as if A and B had been bound directly to the port. In either case, what we get is a
               sequence of XDM <em>document</em> objects, one for each of the resources parsed.</p>
                  <p>One tradeoff is that the override mechanism will be different. We override the first approach by binding
               the pipeline's <code>source</code> port directly to whatever documents we want in place of A and B. We
               override the second approach by providing a different FILELIST document. Alternatively such a FILELIST
               can be referenced instead of included … <code>p:document href="the-filelist.xml</code>, providing us a
               resource that we can maintain separately.</p>
                  <p>This makes the second approach especially appealing if the file list can be derived from some kind of
               metadata resource or, indeed, <code>p:directory-list</code>….</p>
               </section>
            </section>
            <section>
               <h2>Identity pipeline testbed</h2>
               <p>An identity or <q>near-identity</q> or modified-identity pipeline has its uses, including diagnostics. Since
            inputs and outputs are supposed to look the same, any changes they show between inputs and outputs can be
            revealing.</p>
               <p>They are also useful for testing features, for example features for resource acquisition and disposition.
            These are fancy ways to describe how you get data into your pipeline and then out again.</p>
               <p>Additionally, there are actually useful operations supported by a pipeline that pretends to change nothing.
            For example, it can transcode a file from one encoding to another – changing nothing in the data, but
            rewriting it into a different character set.</p>
               <section>
                  <h3>0.01 - what is a <q>document</q>
                  </h3>
                  <h3>0.1 - loading documents known or determinable in advance</h3>
                  <p>The XProc step <code>p:load</code> can be used to load the resource indicated into the pipeline.</p>
                  <p>Watch out, since <code>p:load</code> with <code>href=''</code> – loading the resource at the location
               indicated by the empty string, <code>""</code> – will load the XProc file itself. This is conformant with
               rules for URL resolution.</p>
                  <h3>0.2 - binding a document to an input port</h3>
                  <h3>0.3 - loading documents dynamically on discovery with <code>p:directory-list</code>
                  </h3>
                  <h3>0.4 - saving results to the file system</h3>
                  <h3>0.5 - exposing results on an output port</h3>
               </section>
            </section>
            <section>
               <h2>Probing error space - data conversions</h2>
               <p>Broadly speaking, problems encountered running these conversions fall into two categories, the distinction
            being simple, namely whether a bad outcome is due to an error in the processor and its logic, or in the data
            inputs provided. The term <q>error</q> here hides a great deal. So does <q>bad outcome</q>. One type of bad
            outcome takes the form of failures at runtime - the term <q>failure</q> again leaving questions open. Other
            bad outcomes are not detectable at runtime. If inputs are bad (inconsistent with stated contracts such as
            data validation), processes can run <i>correctly</i> and deliver incorrect results: correctly representing
            inputs, in their incorrectness. Again, the term <i>correct</i> here is underspecified and underdefined,
            except in the case.</p>
               <section>
                  <h3>Converting broken XML or JSON</h3>
               </section>
               <section>
                  <h3>Converting broken OSCAL</h3>
               </section>
               <section>
                  <h3>Converting not-OSCAL</h3>
               </section>
            </section>
            <section>
               <h2>XProc diagnostic how-to</h2>
               <section>
                  <h3>Emitting runtime messages</h3>
               </section>
               <section>
                  <h3>Saving out interim results</h3>
                  <p>
                     <code>p:store</code>
                  </p>
               </section>
            </section>
            <section>
               <h2>Validate early and often</h2>
            </section>
         </section>
         <section class="unit learner"
                  id="oscal-convert_201"
                  data-track="learner">
            <h1>201: XProc in more depth</h1>
            <section>
               <h2>Goals</h2>
               <p>Get more in-depth information about XProc internals.</p>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>You have succeeded in prior exercises, including tools installation and setup. You have seen enough XProc to
            be impressed, but possibly also a little intimidated.</p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>Again, reference is made to pipelines and processes defined for the <a href="../../../projects/oscal-convert/readme.md">oscal-convert project</a>.</p>
            </section>
            <section>
               <h2>Overview: the anatomy of an XProc pipeline</h2>
               <p>Experts in XML can read this section quickly. Newcomers will find some of the concepts here (such as
            namespaces) also apply across XML- and XDM-based technologies including XSLT and Schematron. XDM is the <a href="https://www.w3.org/TR/xpath-datamodel/">XQuery and XPath Data Model</a>, the foundation of XPath,
            XQuery and XSLT.</p>
               <section>
                  <h3>XProc files</h3>
                  <p>An XProc pipeline takes the form of an XML <q>document entity</q>. Unless you are concerned to write an
               XML parser (which is not very likely for XProc's natural constituency), this typically means an XML file,
               that is to say a file encoded in plain text (typically the UTF-8 serialization of Unicode, or
               alternatively another form of <q>plain text</q> supported by your toolkit), and following the rules of
               XML syntax. These rules include how elements and attributes and other XML features are encoded in
                  <b>tags</b> that</p>
                  <ul>
                     <li>Follow the rules with respect to naming, whitespace, delimiters and reserved characters</li>
                     <li>Are correctly balanced, with an end tag for every start tag – for a <code>&lt;start&gt;</code> there
                  must be a <code>&lt;/start&gt;</code> (an end to the start).</li>
                     <li>Are cleanly nested with no overlap: end tags always close the most recently opened element, so no
                  element ever extends beyond the boundaries of its <q>ancestor</q> or containing elements</li>
                  </ul>
                  <p>These rules are fairly simple, and they are well supported by tools designed to read and write XML – to
               respect, follow and enforce the rules on our behalf.</p>
                  <p>Thus they are also quickly and easily internalized, often in only a few minutes of working with XML.</p>
                  <p>Over and above being XML, XProc has some rules of its own ...</p>
                  <section>
                     <h4>XProc document element</h4>
                     <pre>&lt;p:declare-step version="3.0"
   xmlns:p="http://www.w3.org/ns/xproc"
   xmlns:ox="http://csrc.nist.gov/ns/oscal-xproc3"
   type="ox:TEST-XPROC3"
   name="TEST-XPROC3"&gt;
...
&lt;/p:declare-step&gt;</pre>
                  </section>
                  <section>
                     <h4>Namespaces</h4>
                     <pre>   xmlns:p="http://www.w3.org/ns/xproc"
   xmlns:ox="http://csrc.nist.gov/ns/oscal-xproc3"</pre>
                  </section>
                  <section>
                     <h4>@name and @type</h4>
                     <p>On <code>p:declare-step</code>, whether at the top or in a step definition within a pipeline, either
                  or both a <code>@name</code> and a <code>@type</code> are permitted.</p>
                     <pre>   type="ox:TEST-XPROC3"
   name="TEST-XPROC3"&gt;</pre>
                     <p>The name makes it possible to reference the step by name. This is often useful and sometimes more or
                  less essential, for example for providing input to one step from another step's output. (We say
                     <q>more or less essential</q> because the processor will produce names for itself as a fallback, if
                  it needs them, but these are brittle, somewhat opaque – such as <code>!1.2.3</code> – and more
                  difficult to use than the names a developer gives.)</p>
                     <p>Understandably, the name of an XProc must be different from the names given to all the steps in the
                  XProc (which must also be distinct). </p>
                     <p>This repository follows a rule that a step name should correspond to its file base name (i.e., without
                  a filename suffix), so <code>identity_</code> for <code>identity_.xproc</code>, etc. But that is a
                  rule for us, not for XProc in general.</p>
                     <p>A step may also have an assigned <code>@type</code>. Unlike the name, which can be in any namespace or
                  none, the <code>@type</code> must be assigned to a namespace.</p>
                  </section>
               </section>
               <section>
                  <h3>Prologue and body</h3>
                  <p>Keep in mind that to build a pipeline is also to design and deploy a step, since any pipeline can be used
               as a step, and any step may comprise, internally, a pipeline.</p>
                  <p>Since step definitions are more often <q>out of line</q> (in an external file) than inline (in the XProc
               itself), </p>
                  <p>As described in the <a href="https://spec.xproc.org/3.0/xproc/#declare-pipelines">XProc 3.0
                  specification</a>, XProc step declarations can be divided into an initial set of elements for setup
               and configuration, followed by what the specification calls a <i>subpipeline</i>, consisting of a
               sequence of steps to be executed – any steps available, which could be anything. Think of the subpipeline
               as the working parts of the pipeline, while the rest is all about how it is set up.</p>
                  <p>The list of elements that come before the subpipeline is short, which helps: <code>p:import</code>,
                  <code>p:import-functions</code>, <code>p:input</code>, <code>p:output</code>, <code>p:option</code> or
                  <code>p:declare-step</code>. Everything coming after is a step.</p>
                  <p>Within this set of elements (all preceding, none following the subpipeline) XProc further distinguishes
               between the <b>imports</b> for steps and functions, appearing first (elements <code>p:import</code> and
                  <code>p:import-functions</code>), to be followed by elements configuring the step:
                  <code>p:input</code>, <code>p:output</code>, <code>p:option</code> – elements together called the <a href="https://spec.xproc.org/3.0/xproc/#declare-pipelines">prologue</a>.</p>
                  <p>The prologue is used to define ports and options for the pipeline. It can be thought of as the definition
               of the interface for the step as a whole. Defining ports and options is how you give the users of the
               step with the affordances or control points they need to use it. If only a single input is needed, a
               single input port (named <code>source</code>) can be assumed (XXX is this so?), so prologues can be empty
               (and invisible, or not there).</p>
                  <p>Following the prologue, a step may also have local step definitions (<code>p:declare-step</code>). One
               might think of these as macros: maybe they are never used by another pipeline (XXX test: is this even
               possible?), but these locally-defined pipelines can be used internally for logic that is used repeatedly,
               or that warrants separating from the main pipeline for some other reason.</p>
                  <p>After imports, prologue and (optional) step declarations, the step sequence that follows comprises the <a href="https://spec.xproc.org/3.0/xproc/#dt-subpipeline">subpipeline</a>.</p>
                  <p>One other complication: among the steps in the subpipeline, <code>p:variable</code> (a variable
               declaration) and <code>p:documentation</code> (for out-of-band documentation) are also permitted – these
               are not properly steps, but can be useful to have with them.</p>
                  <p>In summary: any XProc pipeline, viewed as a step declaration, can have the following --</p>
                  <ul>
                     <li>Pipeline name and type assignment (if needed), given as attributes at the top</li>
                     <li>
                        <b>Imports</b>: step declarations, step libraries and functions to make available</li>
                     <li>The pipeline <b>prologue</b>: any of the elements named <code>p:input</code>, <code>p:output</code>
                  and <code>p:option</code>, defining this pipeline's ports and options<ul>
                           <li>If no ports are named, assume a single <code>source</code> primary input port, permitting a
                        single document</li>
                        </ul>
                     </li>
                     <li>Optionally (and not common): step declarations for local steps, appearing at
                     <code>p:declare-step</code>. Each of these will have its own name, type, prologue and steps</li>
                     <li>For this pipeline, one or more steps, called the <a href="https://spec.xproc.org/3.0/xproc/#dt-subpipeline">subpipeline</a>
                        <ul>
                           <li>Standard atomic and compound steps in XProc namespace (probably prefixed <code>p:</code>)</li>
                           <li>Imported steps - in their own namespaces (in this repository, prefixed <code>ox:</code>)</li>
                           <li>Variable declarations - <code>p:variable</code>
                           </li>
                        </ul>
                     </li>
                     <li>Finally, as noted above, <code>p:documentation</code> can appear anywhere in a pipeline, but it will
                  be ignored except when appearing inside <code>p:inline</code>. What to do with these is a topic to be
                  covered later.</li>
                  </ul>
                  <p>NB: the pipelines run so far have XML comments demarcating the prologue from the steps.</p>
               </section>
               <section>
                  <h3>XProc steps</h3>
                  <p>The <i>step</i> is the core conceptual unit of XProc. An XProc processing pipeline is composed of steps.
               But a pipeline is also considered as a step in itself. As such it can be used in other pipelines, and so
               on.</p>
                  <p>In other words, steps in XProc are <i>compositional</i>. They are building block assemblies made out of
               smaller building block assemblies. A step is a way to process data. A pipeline is a way of orchestrating
               and arranging such processes.</p>
                  <p>The distinction between pipelines and steps is relative and provisional, but important and useful. The
               pipeline is the logical and actual definition of how your data is to be processed. Every pipeline is
               composed of an arrangement, often a series, of operations. These operations – the steps – include
                  <q>primitives</q>, being designed for generality and reusability for the most common operations. But
               they can also include new steps we have written, as pipelines, and such custom-designed steps can be used
               in combination with the primitives or core compound steps of the language.</p>
                  <p>At a higher level, defining new steps with new step declarations, and using them in combination with
               other steps, is how we manage complexity and change in processing requirements. This strategy maximizes
               adaptability, while also supporting an <q>incremental maturity model</q>, in which all defined processes
               can be improved with reuse, building and testing over time. Careful use and deployment of new steps is
               how we save work, by focusing optimization and making it possible to scale up to address data processing
               requirement sets that are both large and complex.</p>
                  <p>Accommodating this design, an XProc <i>file</i> considered as an XML instance is either of two things: a
                  <i>step declaration</i>, or a collection of such declarations, a <i>library</i>. At the top level,
               recognize an XProc step declaration by the element, <code>p:declare-step</code> (in the XProc namespace)
               and a library by the element <code>p:library</code>.</p>
                  <pre>&lt;p:declare-step xmlns:p="http://www.w3.org/ns/xproc" version="3.0" 
    name="a-first-step"&gt;
...
&lt;/p:declare-step&gt;</pre>
                  <p>Additionally, step declarations can include their own pipeline (step) declarations, making a hybrid
               architecture: the pipeline comprises a step, with its own library not imported but in line. This can also
               be useful.</p>
                  <p>An example of a step library in this repository is <a href="../../../xspec/xspec-execute.xpl">xspec-execute.xpl</a>, which collects several steps supporting XSpec, one each for supporting the
               XSpec testing framework for XSLT, XQuery and Schematron respectively.</p>
                  <p>The advantage of defining a step at the top level, rather than putting all steps into libraries, is that
               such a step can be invoked without prior knowledge of its type name, which is used by XProc to
               distinguish it from other steps. The pipeline simply needs to be presented to the processor, which does
               the rest.</p>
                  <section>
                     <h4>XProc as an XML document</h4>
                     <p>Like any language using XML syntax, XProc depends on a conceptual relation between primitive
                  constructs of the language, and XML syntax, a relation that is ordinarily (and usefully) mediated by
                  means of an (actual or putative) XML <i>data model</i> including elements, attributes, comment nodes,
                  text nodes and so forth. XSLT is such a language, for example: it has its top-level
                     <i>declarations</i>, its <i>template rules</i> and its <i>instructions</i>, all of which are
                  represented using elements in the (standard and most commonly used) XML syntax. Thus, part of learning
                  XSLT is learning that <code>xsl:key</code> is syntax for a <q>key declaration</q> while
                     <code>xsl:template</code> is a <q>template rule</q>.</p>
                     <p>In the same way, elements in XProc's XML vocabulary correspond to structures in XProc - structures
                  which developers and users rely on, as they define both the internals and the <q>control interface</q>
                  for the language as a semantic construct - something that <q>does something</q>. In XProc, those
                  structures include things like <b>documents</b>, <b>content-types</b> (think of <q>formats</q> such as
                  XML and JSON), <b>ports</b> and <b>steps</b>. Some XProc elements represent steps, others do not. (In
                  the same way as an XSLT key declaration is not a template rule.) Learning this difference among others
                  is how you learn XProc.</p>
                     <p>Fortunately, the vocabulary of the language is not very large. Core XProc 3.0 has only 95 elements
                  defined in its namespace (or 99, if you are strictly counting all element types defined, not just the
                  names those elements are given). XProc 3.1 adds a few more. This includes elements for all the core
                  and community-defined steps (recognizable by the prefix <code>p:</code>). Additional to these 95 might
                  be other steps you acquire or define. As with any language, there are parts you will hardly ever use,
                  while other parts are used routinely.</p>
                  </section>
                  <section>
                     <h4>XProc embedded documentation</h4>
                     <p>An example of this is the XProc <code>p:documentation</code> element. This element is designed to
                  carry documentation to a consuming application. Rather than mandate some kind of behavior for
                     <code>p:documentation</code> – something difficult or impossible to do for the general case, or to
                  test –- the XProc rule is <q>anything marked as documentation is for some other consumer</q>, i.e. a
                  documentation engine, not the XProc processor. In other words, a conformant processor <a href="https://spec.xproc.org/3.0/xproc/#documentation">
                           <i>must ignore</i> anything it sees</a>
                  inside <code>p:documentation</code>.</p>
                     <p>There is a small loophole, namely that the effect of <code>p:inline</code> for capturing XML overrides
                  this provision, so if you put <code>p:documentation</code> inside <code>p:inline</code>, it <q>becomes
                     visible</q> as inline content, not as XProc to be operated on (or not).</p>
                     <p>As always it is up to the developer how thoroughly and in what form to include inline documentation.
                  And short of managing a corpus of code documentation along with the code, placing explanatory remarks
                  and code snippets into comments is a widely followed practice, and recommended for its combination of
                  ease and usefulness.</p>
                  </section>
               </section>
               <section>
                  <h3>Atomic and compound steps</h3>
                  <p>Given an understanding of the organization of an XProc pipeline, the focus shifts to the steps
               themselves, which follow a common pattern. Briefly put, an atomic step is any step you use by simply
               invoking it with inputs and options: its logic is self-contained, and the operation it carries out is (at
               least conceptually) <q>single</q> and unified. A compound step, in contrast, combines one or more other
               steps in a <em>subpipeline</em> and manages these together through a single interface.</p>
                  <p>XProc keeps things workable by providing only a few compound steps supporting the identified range of
               needs. This does not prove to be a practical limitation, since all steps including atomic steps can have
               multiple inputs and outputs, distinguished by type and role. (For example, a validation step might output
               both a copy of the input, potentially annotated, along with a validation report.) Atomic steps are not
               necessarily simple, and may include compound steps in their own subpipelines, either externally or even
               within the same step declaration. Accordingly, compound steps are not necessarily more complex than
               atomic steps: they are useful because they handle common contingencies such as splicing (with
                  <code>p:viewport</code>), splitting (with <code>p:for-each</code>, perform an operation in parallel
               over a set of inputs, not a single document), conditionals (<code>p:if</code>, <code>p:choose</code>) and
               exception handling (<code>p:try</code> with <code>p:catch</code> and <code>p:finally</code>).</p>
                  <p>Here are all the compound steps. All others are atomic steps.</p>
                  <ul>
                     <li>
                        <a href="https://spec.xproc.org/3.0/xproc/#p.group"
                           style="color: rgb(3, 69, 117); text-decoration: none; border-bottom: 1px solid rgb(112, 112, 112); padding: 0px 1px; margin: 0px -1px; font-family: sans-serif; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: -120px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal;">
                           <code class="tag-element language-construct"
                                 style="font-family: Consolas, Monaco, &#34;Andale Mono&#34;, monospace; font-size: 16px; break-inside: avoid; hyphens: none; text-transform: none; text-align: left; white-space: pre; color: black; text-shadow: white 0px 1px; direction: ltr; word-spacing: normal; word-break: normal; tab-size: 4; padding: 0.1em; border-radius: 0.3em;">p:group</code>
                        </a>
                  - group a subpipeline (step sequence) into a single logical step</li>
                     <li>
                        <a href="https://spec.xproc.org/3.0/xproc/#p.if"
                           style="color: rgb(3, 69, 117); text-decoration: none; border-bottom: 1px solid rgb(112, 112, 112); padding: 0px 1px; margin: 0px -1px; font-family: sans-serif; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: -120px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal;">
                           <code class="tag-element language-construct"
                                 style="font-family: Consolas, Monaco, &#34;Andale Mono&#34;, monospace; font-size: 16px; break-inside: avoid; hyphens: none; text-transform: none; text-align: left; white-space: pre; color: black; text-shadow: white 0px 1px; direction: ltr; word-spacing: normal; word-break: normal; tab-size: 4; padding: 0.1em; border-radius: 0.3em;">p:if</code>
                        </a>
                  - execute a subpipeline conditionally</li>
                     <li>
                        <a href="https://spec.xproc.org/3.0/xproc/#p.choose"
                           style="color: rgb(3, 69, 117); text-decoration: none; border-bottom: 1px solid rgb(112, 112, 112); padding: 0px 1px; margin: 0px -1px; font-family: sans-serif; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: -120px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal;">
                           <code class="tag-element language-construct"
                                 style="font-family: Consolas, Monaco, &#34;Andale Mono&#34;, monospace; font-size: 16px; break-inside: avoid; hyphens: none; text-transform: none; text-align: left; white-space: pre; color: black; text-shadow: white 0px 1px; direction: ltr; word-spacing: normal; word-break: normal; tab-size: 4; padding: 0.1em; border-radius: 0.3em;">p:choose</code>
                        </a>
                  - execute a subpipeline conditionally (<code>switch/case</code> operator)</li>
                     <li>
                        <a href="https://spec.xproc.org/3.0/xproc/#p.for-each"
                           style="color: rgb(3, 69, 117); text-decoration: none; border-bottom: 1px solid rgb(112, 112, 112); padding: 0px 1px; margin: 0px -1px; font-family: sans-serif; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: -120px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal;">
                           <code class="tag-element language-construct"
                                 style="font-family: Consolas, Monaco, &#34;Andale Mono&#34;, monospace; font-size: 16px; break-inside: avoid; hyphens: none; text-transform: none; text-align: left; white-space: pre; color: black; text-shadow: white 0px 1px; direction: ltr; word-spacing: normal; word-break: normal; tab-size: 4; padding: 0.1em; border-radius: 0.3em;">p:for-each</code>
                        </a>
                  - produce subpipeline results for each member of a sequence of inputs (documents or nodes)</li>
                     <li>
                        <a href="https://spec.xproc.org/3.0/xproc/#p.viewport"
                           style="color: rgb(3, 69, 117); text-decoration: none; border-bottom: 1px solid rgb(112, 112, 112); padding: 0px 1px; margin: 0px -1px; font-family: sans-serif; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: -120px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal;">
                           <code class="tag-element language-construct"
                                 style="font-family: Consolas, Monaco, &#34;Andale Mono&#34;, monospace; font-size: 16px; break-inside: avoid; hyphens: none; text-transform: none; text-align: left; white-space: pre; color: black; text-shadow: white 0px 1px; direction: ltr; word-spacing: normal; word-break: normal; tab-size: 4; padding: 0.1em; border-radius: 0.3em;">p:viewport</code>
                        </a>
                  - reproduce outputs, except splicing subpipeline results in place of matched nodes (elements) in the
                  input</li>
                     <li>
                        <a href="https://spec.xproc.org/3.0/xproc/#p.try"
                           style="color: rgb(3, 69, 117); text-decoration: none; border-bottom: 1px solid rgb(112, 112, 112); padding: 0px 1px; margin: 0px -1px; font-family: sans-serif; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: -120px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal;">
                           <code class="tag-element language-construct"
                                 style="font-family: Consolas, Monaco, &#34;Andale Mono&#34;, monospace; font-size: 16px; break-inside: avoid; hyphens: none; text-transform: none; text-align: left; white-space: pre; color: black; text-shadow: white 0px 1px; direction: ltr; word-spacing: normal; word-break: normal; tab-size: 4; padding: 0.1em; border-radius: 0.3em;">p:try</code>
                        </a>
                  - execute a subpipeline, and deliver its results, or if it fails, run a fallback subpipeline given in
                  a <code>p:catch</code>
                     </li>
                  </ul>
                  <p>Additionally to these elements, XProc subpipelines may contain variable declarations
                  (<code>p:variable</code>) and documentation (<code>p:documentation</code>), as noted.</p>
               </section>
               <section>
                  <h3>Namespaces and extension steps</h3>
                  <p>We recognize steps because we either recognize them by name - for standard steps in the <code>p:</code>
               (XProc) namespace such as <code>p:filter</code> and <code>p:add-attribute</code> - or sometimes by
               process of elimination – because they cannot be anything else. This is because extension steps, whether
               written or acquired, can be named anything. Fortunately, extension steps in XProc take the form of
               elements in an <em>extension namespace</em>. Generally speaking, that is, any element not prefixed with
                  <code>p:</code> is treated as out of scope for XProc and to be ignored, while subject to evaluation as
               an extension.</p>
                  <p>But this is an important category, since such extensions may include XProc steps whose functioning is
               core to the pipeline as a whole.</p>
                  <details>
                     <summary>Question: Where are extension steps used in the XProcs run so far?</summary>
                     <p>One answer:
                  The <a href="./../../../smoketest/TEST-XSPEC.xpl">XSpec smoke test</a> calls an extension step named
                     <code>ox:execute-xspec</code>, defined in an imported pipeline. In this document, the prefix
                     <code>ox</code> is bound to a utility namespace,
                  <code>http://csrc.nist.gov/ns/oscal-xproc3</code>.</p>
                     <p>In an XProc pipeline (library or step
                  declaration) one may also see additional namespaces, including</p>
                     <ul>
                        <li>The namespaces needed for XSLT, XSD, or other supported technology</li>
                        <li>One or more namespaces deployed by the XProc author to support either steps or internal operations
                     (for example, XSLT functions)</li>
                        <li>The namespace <code>http://www.w3.org/ns/xproc-step</code>, usually associated with the name
                     prefix <code>c:</code>. This namespace is designated by XProc in order to help standardize the
                     interfaces (inputs and outputs) supported by standard steps.</li>
                        <li>The namespace <code>http://www.w3.org/ns/xproc-error</code>, for XProc's error reporting</li>
                     </ul>These declarations (often but not always at the top of the document) are critically important for
               XPath and hence for the correct operation of your pipelines. See <a href="https://spec.xproc.org/3.0/xproc/#namespaces">the specification</a> for more
               information.</details>
               </section>
               <section>
                  <h3>Schema for XProc 3.0</h3>
                  <p>See coverage of <a href="../walkthrough/walkthrough_399_src.html"
                        class="LessonUnit">XProc, XML and XDM (the XML
                  Data Model)</a> in the prior lesson unit for a link to the schema for XProc.</p>
               </section>
            </section>
            <section>
               <h2>Some breaking and making</h2>
               <p>Every project you examine provides an opportunity to alter pipelines and see how they fail when not encoded
            correctly – when <q>broken</q>, any way we can think of breaking them. Then build good habits by repairing
            the damage. Experiment and observation bring learning.</p>
               <p>After reading this page, perform some more disassembly / reassembly. Here are a few ideas:</p>
               <ul>
                  <li>Switch out the value of an <code>@href</code> on a <code>p:document</code> or <code>p:load</code> step.
               See what happens when the file it points to is not actually there.</li>
                  <li>There is a difference between <code>p:input</code>, used to configure a pipeline in its prologue, and
                  <code>p:load</code>, a step that loads data. Ponder what these differences are. Try changing a
               pipeline that uses one into a pipeline that uses the other.</li>
                  <li>Similarly, there is a difference between a <code>p:output</code> configuration for a pipeline, and a
                  <code>p:store</code> step executed by that pipeline. Consider this difference and how we might define
               a rule for when to prefer one or the other. How is the pipeline used - is it called directly, or intended
               for use as a step in other pipelines? How is it to be controlled at runtime?</li>
                  <li>Try inserting <code>p:store</code> steps into a pipeline to capture intermediate results, that is, the
               output of any step before they are processed by the next step. Such steps can aid in debugging, among
               other uses.</li>
                  <li>
                     <code>@message</code> attributes on steps provide messages for the runtime traceback. They are optional
               but this repo follows a rule that any <code>p:load</code> or <code>p:store</code> should be provided with
               a message. Why?</li>
                  <li>A <code>p:identity</code> step passes its input unchanged to the next step. But can also be provided
               with a <code>@message</code>.</li>
               </ul>
               <p>After breaking anything, restore it to working order. Create modified copies of any pipelines for further
            analysis and discussion.</p>
               <ul>
                  <li>Concept: copy and change one of the pipelines provided to acquire a software library or resource of your
               choice.</li>
               </ul>
            </section>
            <section>
               <h2>What could possibly go wrong?</h2>
               <p>When coping with errors, syntax errors are relatively easy. But anomalous inputs, especially invalid inputs,
            can result in lost data. (A common reason data is not valid even when it appears to be is that it has
            foreign unknown contents, or contents out of place - the kinds of things that might fail to be converted.)
            The most important concern when engineering a pipeline is to see to it that no data quality problems are
            introduced inadvertantly. While in comparison to syntax or configuration problems, data quality issues can
            be subtle, there is also good news: the very same tools we use to process inputs into outputs, can also be
            used to test and validate data to both applicable standards and local rules.</p>
               <p>Generally speaking, OSCAL maintains <q>validation parity</q> between its XML and JSON formats with respect
            to their schemas. That is to say, the XSD (XML schema) covers essentially the same set of rules for OSCAL
            XML data as the JSON Schema does for OSCAL JSON data, accounting for differences between the two notations,
            the data models and how information is mapped into them. A consequence of this is that valid OSCAL data,
            either XML or JSON, can reliably be converted to valid data in the other notation, while invalid data may
            not be converted at all, resulting in gaps or empty results.</p>
               <p>For this and related reasons on open systems, the working principle in XML is often to formalize a model
            (typically by writing and deploying a schema) as early as possible - or adopt a model already built - as a
            way to institute and enforce schema validation as a <b>prerequisite</b> and <b>primary requirement</b> for
            working with any data set. Validation against schemas is covered in a subsequent lesson unit (coming soon
            near you).</p>
               <section>
                  <h3>Intercepting errors</h3>
                  <p>One way to manage the problem of ensuring input quality is to validate on the way in, either as a
               dependent (prerequisite) process, or built into a pipeline. Whatever you want to do with invalid inputs,
               including ignoring them and producing warnings or runtime exceptions, can be defined in a pipeline much
               like anything else.</p>
                  <p>In the <a href="../../../projects/oscal-publish/publish-oscal-catalog.xpl">publishing demonstration
                  project folder</a> is an XProc that valides XML against an OSCAL schema, before formatting it. The
               same could be done for an XProc that converts the data into JSON - either or both before or after
               conversion.</p>
                  <p>Learn more about recognizing and dealing with errors in <a href="oscal-convert_102_src.html"
                        class="LessonUnit">Lesson 102</a>, or continue on to the next project, oscal-validate, for more on
               validation of documents and sets of documents.</p>
               </section>
            </section>
            <section>
               <h2>for 599: XProc for JSON</h2>
               <p>map objects; steps for working with them; interim p:store as debug method; output ports to see results
            (final and intermediate) or bind them</p>
            </section>
            <section>
               <h2>for 599: YAML TODO</h2>
               <p>map objects; steps for working with them</p>
            </section>
            <section>
               <h2>for 599: XProc port bindings</h2>
               <p>This is actually a .bat or .sh exercise - write a script that invokes XProc with a binding to a runtime
            argument</p>
               <p>Thus, a script <code>convert-oscal-catalog-xml.sh mycatalog.xml</code> could produce
               <code>mycatalog.json</code> from <code>mycatalog.xml</code> etc.</p>
               <p>Such a script could live in the project directory - do we want an Issue for this work item? </p>
            </section>
            <section>
               <h2>for 599: URIs and URI schemes</h2>
               <p>As described in <a href="https://spec.xproc.org/master/head/xproc/#err.inline.D0012">the XProc
               specification</a>, it is up to implementations to define supported URI schemes and data retrieval
            mechanics, including XML catalogs to support resource caching and indirection, etc.</p>
            </section>
            <section>
               <h2>for 599: round tripping as process test</h2>
            </section>
         </section>
         <section class="unit maker"
                  id="oscal-convert_350"
                  data-track="maker">
            <h1>350: Namespaces in XML and XProc</h1>
            <section>
               <h2>Goals</h2>
               <p>Learn enough about namespaces in XML to be able to make sense of XProc's handling of embedded vocabularies,
            whether extending its capabilities or for the purpose of embedding (literal) data sets.</p>
               <p>Be no longer mystified by prefixed names such as <code>p:sleep</code>, <code>xsl:template</code> or
               <code>ox:oscal-xml-as-json</code> as a technology-wide convention for helping to disambiguate the
            semantics of different vocabularies, when mixed and in general.</p>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>None. If you don't need to know about XML's namespace mechanism, you can gladly skip this coverage.</p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>A <a href="https://www.w3.org/TR/REC-xml-names">technical specification</a> of this mechanism was published
            by W3C in 2009, and remains the authoritative source.</p>
               <p>XXX A namespaces worksheet XProc provides a place to experiment....</p>
            </section>
            <section>
               <h2>XML and namespaces</h2>
               <p>XProc like many XML technologies uses the XML namespace mechanism to disambiguate between mixed
            vocabularies.</p>
               <p>Using namespace-qualified names in the form of <em>colonized names</em> (such as <code>p:try</code>)  makes
            it possible to distinguish between <code>p:try</code> and <code>xsl:try</code> reliably (to use a real
            example).</p>
               <p>Moreover, a formal mechanism defined in XML syntax (<em>namespace declaration</em> by way of attributes)
            enables associating the prefixes in a given scope with a controlled set of authority references (in the form
            of namespace URIs). Thus any namespace, considered as set of prefixed names under by a given declaration)
            can easily with its putative owner, proprietor or maintainer, in a way that lets them decide the fine
            distinctions: so <code>http://www.w3.org/1999/XSL/Transform</code> for XSLT,
               <code>http://www.w3.org/ns/xproc</code> for XProc and so forth: same maintainance umbrella, different
            applications.</p>
            </section>
            <section>
               <h2>Namespace fixup and namespace cleanup steps</h2>
               <p>XProc specifies a process called <em>namespace fixup</em> that constitutes essentially a set of rewrite
            rules for a tree of elements and attributes with qualified names, in order to normalize and streamline the
            deployment of namespaces, with benefits in file size and legibility. You should think of namespace fixup as
            something the processor might do on your behalf at any time, and a good thing. Minimize its impacts by
            avoiding new namespaces where possible, and controlling namespaces in use.</p>
               <p>While namespace fixup will help, it cannot optimize for your case. The step <code>p:delete-namespace</code>
            is a common remedy for <em>inflamed namespaces</em>, a condition that happens to XML that has been handled
            recklessly by too many handlers with too many namespaces. Also, <code>p:namespace-rename</code>.</p>
            </section>
            <section>
               <h2>Namespace tips and tricks XXX</h2>
               <section>
                  <h3>Coining new namespaces</h3>
               </section>
               <section>
                  <h3>On-the-fly namespace declarations</h3>
               </section>
               <section>
                  <h3>Overloading prefixes</h3>
               </section>
               <section>
                  <h3>Matching with namespace wildcard</h3>
                  <p>For example, <code>match="*:p"</code> will match any <code>p</code> element in any namespace.</p>
               </section>
            </section>
         </section>
         <section class="unit maker"
                  id="oscal-convert_401"
                  data-track="maker">
            <h1>401: XProc, XML, JSON and content types</h1>
            <section>
               <h2>Goals</h2>
               <p>Understand a little more about JSON and other data formats in an XML processing environment</p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>A <a href="../../worksheets/CONTENT-TYPE_worksheet.xpl">content-types worksheet XProc</a> is offered for
            trying out content-type options on XProc inputs and outputs.</p>
               <p>The pipeline <a href="../../worksheets/READ-JSON-TESTING.xpl">READ-JSON-TESTING.xpl</a> provides an
            experimental surface for working functionality specifically related to JSON and XDM map objects.</p>
               <p>Find more treatment in <a href="oscal-convert_402_src.html"
                     class="LessonUnit">the next lesson unit</a>.
            This is a topic you can also learn by through trial and error.</p>
            </section>
            <section>
               <h2>Exercise some options</h2>
               <p>The worksheets just cited provide an opportunity to try out <code>content-type</code> configuration options.
            Note how you can specify a content type that will serve as a constraint on inputs and outputs, analogous in
            some ways to the type signature on a function. And the step <code>p:content-type</code> serves to cast one
            content type to another, according to <a href="https://spec.xproc.org/3.0/steps/#c.cast-content-type">rules
               given in the Specification</a>. Note that for this step to work, both inputs and outputs must conform to
            certain requirements: not everything can be cast!</p>
               <ul>
                  <li>Try specifying a content-type on input or outputs to constrain the inputs or outputs, producing errors
               for mismatches</li>
                  <li>Try using a cast-content-type step to explicitly cast between content types.</li>
                  <li>Use the function <code>p:document-properties(.,'content-type')</code> to bring back the content type of
               a document on a port or in a pipeline. In XPath, <code>.</code> refers to an designated as the (dynamic)
               processing context: so <code>p:document-properties($doc,'content-type')</code> works for any $doc
               considered by XProc to be or serve as a <em>document</em>.</li>
                  <li>Interestingly, this means we can expect to find content-type='application/json' whenever an XProc
               document is nothing more than an object or map – as can happen, by design.</li>
               </ul>
               <p>
                  <a href="../../worksheets/READ-JSON-TESTING.xpl">READ-JSON-TESTING.xpl</a> is a sandbox for playing with
            JSON objects as XDM maps. The <a href="../../worksheets/CONTENT-TYPE_worksheet.xpl">content-types
               worksheet</a> is set up for trying content-type options on inputs and outputs. </p>
            </section>
         </section>
         <section class="unit learner"
                  id="oscal-convert_402"
                  data-track="learner">
            <h1>402: XProc, XML, JSON and content types</h1>
            <section>
               <h2>Goals</h2>
               <p>Understand a little more about JSON and other data formats in an XML processing environment</p>
            </section>
            <section>
               <h2>Resources</h2>
               <p>A <a href="../../worksheets/CONTENT-TYPE_worksheet.xpl">content-types worksheet XProc</a> is offered for
            trying out content-type options on XProc inputs and outputs. If you only have thirty minutes, consider
            looking at it before reading further.</p>
               <p>XProc content types are closely tied to its definition of a <em>document</em>, an object for which a string
            property <code>content-type</code> indicates the expected or nominal content type.See links given in the
            remarks below. This is a topic you can also learn by through trial and error.</p>
            </section>
            <section>
               <h2>XProc documents and content types</h2>
               <p>XProc needs a contract or working agreement with the world at large regarding how to refer to the various
            kinds of things XProc consumes and produces. The XProc concept and deployment of <code>content-type</code>
            properties is one of the main ways it does this. Read about XProc's content types<a href="https://spec.xproc.org/3.0/xproc/#documents"> in the specification, which normatively defines all
               the terms</a>.</p>
               <p>The short and easier story is that XProc's content types are aligned closely with media types or <q>file
               types</q> as they are defined broadly across Internet standards and protocols. Web developers will have a
            head start if they know how tools already distinguish between file and application formats in web
            technologies using identifiers such as <code>text/html</code> or <code>application/svg+xml</code>.</p>
               <p>The longer story is that by relying on content types, XProc can effectively divide the world, like Gaul,
            into three parts, thereby making it possible to divide and conquer – or at least to recognize and negotiate
            with.</p>
               <section>
                  <h3>XML and XML-like content</h3>
                  <p>Always our first choice for working with in XProc, this category include these content types:</p>
                  <ul>
                     <li>
                        <code>text/html</code> and <code>application/xhtml+xml</code> are the <a href="https://spec.xproc.org/3.0/xproc/#html-documents">HTML media types</a>
                     </li>
                     <li>
                        <code>application/xml</code>, <code>text/xml</code>, and all types matching
                        <code>
                           <i>something</i>/<i>something</i>+xml</code> except <code>application/xhtml+xml</code>
                  constitute the <a href="https://spec.xproc.org/3.0/xproc/#xml-documents">XML media types</a>
                     </li>
                  </ul>
                  <p>Since XProc has XPath, XML is entirely transparent and natural to work with. XSLT and XQuery give us
               optimized methods for transformations and queries at scale, as soon as the source is recognizable as some
               kind of XML.</p>
                  <p>Since it is either XML or has well-defined mappings into XML, HTML can count as a specialized form of XML
               for XProc purposes. This is a joy:  it means HTML is no different except in how it is read and written,
               and sometimes not even then. In particular, within XProc, XPath and other XML tools (such as XSLT and
               Schematron) both work with HTML the same as they do with XML.</p>
               </section>
               <section>
                  <h3>JSON and other text-based formats</h3>
                  <ul>
                     <li>
                        <code>text/<i>something</i>
                        </code> including <code>text/plain</code>, except for
                     <code>text/xml</code> and <code>text/html</code> are the <a href="https://spec.xproc.org/3.0/xproc/#text-documents">text media types</a>
                     </li>
                     <li>
                        <code>application/json</code> and any <code>application/<i>something</i>+json</code> are the <a href="https://spec.xproc.org/3.0/xproc/#json-documents">JSON media types</a>
                     </li>
                  </ul>
                  <p>Both these types are accommodated straightforwardly as XDM objects: in the case of plain text, we have
               what amounts to a string, while JSON becomes an appropriate XDM type, most often a map, which is
               isomorphic to a JSON object with properties.</p>
                  <p>The <a href="https://spec.xproc.org/lastcall-2024-08/head/ixml/">XProc step <code>p:ixml</code>
                     </a> is
               provided to processors supporting <a href="https://invisiblexml.org/">Invisible XML</a>. It enables
               parsing of text strings according to a grammar and delivering the resulting parse tree in an XML
               representation.</p>
                  <p>As for JSON, it can conveniently be cast into an XML vocabulary defined by XPath, using the same
               semantics as XPath 3.1 <code>fn:json-to-xml($json-string)</code>, which produces XML using a vocabulary
               for map objects defined by XPath. One way to do this is with the <code>p:cast-content-type</code> step,
               designed for the purpose, indicating an XML content type <a href="https://spec.xproc.org/3.0/xproc/#specified-content-types">or the shortcut <code>xml</code>
                     </a>. </p>
                  <p>Yet it is also important and useful to keep in mind how an <a href="https://spec.xproc.org/3.0/xproc/#documents">XProc document</a> does not have to be XML, or
               indeed any XDM document (node) or element. The XProc concept is general enough to allow for any XDM data
               object can be provided with properties in XProc (base URI, content-type and when applicable serialization
               settings) that enable it to be passed through an XProc pipeline, operated on by steps and made available
               on their ports. At all times, a serialization for such a document – even a value or fragment of XDM such
               as a map, as distinct from an XML element tree we can easily serialize as XML – is nevertheless available
               as long as it is regarded as JSON, because XDM objects, with some limitations, are readily expressible as
               JSON, and conversely JSON objects of whatever identified (primitive) type (object, array, string, number,
               boolean etc.) can be considered <q>at home</q> within the XProc context if only they have an XDM analog,
               as they mainly do. Significantly, as XPath map objects, arbitrary JSON objects of whatever size and
               extent can now be queried using XPath – a feature that XProc can take advantage of.</p>
                  <p>See also: <a href="https://www.w3.org/TR/xpath-functions-31/#json-to-maps-and-arrays">XPath 3.1 on maps,
                  arrays and JSON</a>.</p>
                  <section>
                     <h4>XPath maps, with operators and functions</h4>
                     <p>Readers who have no prior experience with XPath 3.1 (or later) may never have seen the XPath
                     <em>map</em> and <em>array</em> objects or the functions and operations associated with them. Some
                  syntax might look like (and it is no mistake if this is familiar to JSON users):</p>
                     <table>
                        <tbody>
                           <tr>
                              <th>XPath expression</th>
                              <th>Explanation</th>
                           </tr>
                           <tr>
                              <td>map { "a": "A", "b": "B" }</td>
                              <td>A map with two entries, with keys "a" and "b" </td>
                           </tr>
                           <tr>
                              <td>map { "a": "A", "b": "B" }?a</td>
                              <td>The value "a" returned from a map, using lookup operator</td>
                           </tr>
                           <tr>
                              <td>map { "a": "A", "b": "B" } return $m('b')</td>
                              <td>The value "b" returned using function call syntax</td>
                           </tr>
                        </tbody>
                     </table>
                     <p>In XPath, a map's keys (keywords for its entries) can be any atomic value, and an entry's value can be
                  anything, including nodes (roots of trees) or arbitrary sequences. The subset of XPath maps whose keys
                  are strings and whose values, roughly, are amenable to serialization (so strings and numbers and
                  arrays and maps, but not node trees), aligns with JSON.</p>
                     <p>For the word on XPath maps, see the <a href="https://www.w3.org/TR/xpath-31/#id-maps">XPath 3.1
                     Recommendation on the topic</a>.</p>
                  </section>
               </section>
               <section>
                  <h3>Binaries and <q>other</q>
                  </h3>
                  <p>Support for any content types not named above (and thus in a recognizable category for purposes of
               parsing strategy) must necessarily fall on implementors. Certain standard steps such as
                  <code>p:unarchive</code> and its relatives are useful to define for certain at-large binary file
               types, with effective standardization for certain content types (compressed files i.e. zips and the
               like); handling for arbitrary or unknown files and file types is a different matter.</p>
                  <p>Depending on your processor some binary formats such as raster image formats might be effectively opaque,
               with only some metadata readable; other formats such as compression formats are simply wrappers for other
               resources. The semantics will vary according to the processor and file type(s) implicated.</p>
                  <p>This does not mean that such content types cannot be effectively standardized and supported as such. One
               important member of this category is a file representing a zipped or compressed file set, as defined for
               the three steps <code>p:archive</code>, <code>p:archive-manifest</code>, and <code>p:unarchive</code>.
               Due to felicitous choices by early engineers, common word processor and spreadsheet formats including
                  <code>docx</code>, <code>xlsx</code>, <code>odt</code> and <code>ods</code> can all be uncompressed to
               reveal sets of files including legible XML files – making these formats at least relatively accessible
               for XProc.</p>
                  <p>
                     <code>content-type="*/*</code> is a match for <q>any content type</q>, very useful for handling arbitrary
               inputs, to the extent the processor supports them (for example moving and copying even if not
               reading).</p>
               </section>
            </section>
         </section>
      </section>
      <section class="lesson"
               id="courseware"
               name="courseware">
         <section class="unit observer"
                  id="courseware_101"
                  data-track="observer">
            <h1>Courseware 101: Producing this tutorial</h1>
            <section>
               <h2>Goals</h2>
               <p>Understand better how this tutorial is produced</p>
               <p>See an example of a small but lightweight and scalable publishing system can be implemented in XProc and
            XSLT</p>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>None.</p>
               <p>Readers who wish not only to inspect and refresh tutorial contents, but also to edit or extend, or alter the
            tutorial pipelines, are invited to look at <a href="courseware_219_src.html"
                     class="LessonUnit">the next
               exercise (lesson unit)</a>.</p>
            </section>
            <section>
               <h2>Resources</h2>
               <ul>
                  <li>Everything in the course you have seen so far</li>
                  <li>Everything else you have seen relating to XProc</li>
                  <li>Your own problems</li>
                  <li>Your own examples</li>
               </ul>
            </section>
            <section>
               <h2>Tutorial production pipelines</h2>
               <p>The source files for these tutorials are all stored in the repository in a source directory, and maintained
            in HTML format. The expectation is that all files will be represented as valid and complete HTML 5 in XML
            syntax, i.e. XHTML to be treated as an HTML document type. However, not all files in this subdirectory are
            used as source materials; this is only where they are stored and maintained.</p>
               <p>At the top of the tutorial structure, a file <a href="../../lesson-plan.xml">lesson-plan.xml</a> is used as
            a publication driver or configuration file, when read as a sequence of links back to folders. Each folder
            named as a <code>Lesson/@key</code> is read, with all HTML files surnamed <code>_src.html</code> from that
            folder considered to be tutorial source materials, in nominally alphabetic order. The tutorial as a whole is
            built by reading each of these files, converting it to Markdown (with adjustments), and producing indexes to
            the entire set, all done by writing files into the <a href="sequence/">sequence directory</a>. Such a
            Markdown file set can be read and edited in Github in the usual way, or refreshed by running a production
            pipeline again.</p>
               <p>The authoring model and its design rationales as well as its tooling support, including automated proof
            checking under CI/CD, is described in a <a href="courseware_219_src.html"
                     class="LessonUnit">subsequent
               lesson unit</a>. Authoring in HTML rather than Markdown provides all kinds of leverage for ad-hoc
               <q>tutorial semantics</q> especially with the help of a structured (tagless) editor.</p>
               <p>Each of the pipelines at the top performs a specific task with respect to tutorial production.</p>
               <p>As always, pipelines should be provided with explanatory comments.</p>
               <p>When reading and writing files to file systems, the usual security considerations apply.</p>
               <section>
                  <h3>
                     <a href="../../PRODUCE-TUTORIAL-PREVIEW.xpl">PRODUCE-TUTORIAL-PREVIEW</a>
                  </h3>
                  <p>Generates a preview (reading) version of the tutorial, for proofing.</p>
               </section>
               <section>
                  <h3>
                     <a href="../../PRODUCE-TUTORIAL-MARKDOWN.xpl">PRODUCE-TUTORIAL-MARKDOWN</a>
                  </h3>
                  <p>Generates Markdown from the HTML source data, populating an output folder with these results.</p>
               </section>
               <section>
                  <h3>
                     <a href="../../PRODUCE-TUTORIAL-TOC.xpl">PRODUCE-TUTORIAL-TOC</a>
                  </h3>
                  <p>Generates a Table of Contents in Markdown, saving it as <a href="../../sequence/lesson-sequence.md">lesson-sequence.md</a> in a location where it will function on publication (by the repository).</p>
               </section>
               <section>
                  <h3>
                     <a href="../../PRODUCE-PROJECTS-ELEMENTLIST.xpl">PRODUCE-PROJECTS-ELEMENTLIST</a>
                  </h3>
                  <p>Generates an index of XProc elements used in projects in the repository, stored as<a href="../../sequence/element-directory.md">element-directory.md</a>.</p>
               </section>
            </section>
         </section>
         <section class="unit maker"
                  id="courseware_219"
                  data-track="maker">
            <h1>Courseware 219: Learn by Teaching</h1>
            <section>
               <h2>Goals</h2>
               <p>Help yourself, your team and allies.</p>
               <p>Produce a useful spin-off from a task or problem you need to master anyway.</p>
               <p>Learn not only by doing but by writing it down for yourself and others</p>
            </section>
            <section>
               <h2>Prerequisites</h2>
               <p>Those with no prior experience in XSLT or declarative markup might think about that before venturing into
            these waters. This is an awesome exercise but faking it takes you only so far. This lesson segment assumes
            you will write content in HTML as well as giving you the chance to extend XProc and XSLT as you see fit.</p>
               <p>Writing HTML by hand can be arduous; accordingly, for producing tutorial pages we have used a structured XML
            authoring environment (oXygen XML Author) with many features including styling in display; full control over
            styling; Schematron rules in the background along with UI support for content corrections according to those
            rules; etc.</p>
               <p>However, any text editor or programmers' coding environment also works (to whatever extent generic HTML is
            supported), and Schematrons applied to HTML files can be run in XProc (as described).</p>
            </section>
            <section>
               <h2>Resources</h2>
               <ul>
                  <li>Everything in the course you have seen so far</li>
                  <li>Everything else you have seen relating to XProc</li>
                  <li>Your own problems</li>
                  <li>Your own examples</li>
               </ul>
            </section>
            <section>
               <h2>Improve or enhance a lesson or lesson unit</h2>
               <p>Astute readers will have observed that a markup-based deployment invites editing. But the authoring or data
            acquisition model of this tutorial is not Markdown-based - Markdown is paradoxically not used for its
            intended purpose but as one of several <b>publication</b> formats for this data set, which is currently
            written in an XML-based HTML5 tag set defined for the project. By writing, querying and indexing in XHTML we
            can use XProc from the start. Extensibility and flexibility in publication is one of the strengths - to
            publish a new or rearranged tutorial sequence can be done with a few lines and commands. A drag and drop
            interface supporting XProc makes this even easier, while it is already installed and running under CI/CD,
            meaning both editorial and code quality checks can be done with every commit.</p>
               <p>Improving a page is as simple as editing the copy found in XXX and XXX</p>
               <p>Making and deploying a new pages is a little harder: XXX</p>
               <section>
                  <h3>Apply Schematron to your edits</h3>
               </section>
            </section>
            <section>
               <h2>Create a new lesson unit ('area')</h2>
            </section>
            <section>
               <h2>Produce a new project and document it with a tutorial</h2>
            </section>
         </section>
      </section>
   </body>
</html>