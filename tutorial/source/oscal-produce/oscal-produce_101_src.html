<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <title>101: Producing OSCAL from a publication format</title>
      <meta charset="utf-8" />
   </head>
   <body data-track="observer">
      <h1>101: Producing OSCAL from a publication format</h1>
      <section>
         <h2>Goals</h2>
         <p>Learn how high-quality XML can be produced from uncontrolled source data, with several examples.</p>
         <p>Observe how a deterministic data processing framework can be tuned or programmed to resolve anomalies in bad
            inputs, producing a well-formatted, cleanly encoded edition at a higher level of quality and capability,
            using a traceable and verifiable process.</p>
         <p>Along the way, learn something about XProc; XSLT transformations; XML; NISO STS format (a standard encoding
            for supporting publication in electronic formats); OSCAL; the NIST Cybersecurity and Privacy Reference Tool
            (CPRT); the US Digital Service, US Army field manuals and documentation; and the focus of FM 6-22:
            Leadership and leadership development.</p>
      </section>
      <section>
         <h2>Prerequisites</h2>
         <p>You have succeeded in prior exercises, including tools installation and setup.</p>
         <p>You have some understanding of OSCAL if not familiarity with it, possibly having seen or used public OSCAL
            examples such as NIST Special Publication (SP) 800-53 encoded as an OSCAL catalog.</p>
      </section>
      <section>
         <h2>Resources</h2>
         <p>Several projects in the repository (at time of writing) produce OSCAL data from inputs that are not OSCAL.
            They each produce the same kind of result: an OSCAL catalog (XML document). Beyond this they represent a
            range of cases in both complexity and goals:</p>
         <ul>
            <li>USDS Playbook – 13 OSCAL controls (high level) from a simple web page produced by the US Digital
               Service: Guidance for the design and implementation of online (digital) services </li>
            <li>NIST SP 800-171 from NIST Computer Cybersecurity and Privacy Reference Tool (CPRT) JSON - control
               catalog </li>
            <li>US Army Field Manual 6-22 - via HTML from PDF source, with NISO STS format as an additional result -
               Chapter 4 on Leadership Development</li>
         </ul>
         <p><i>Caution: all produced versions of these public documents are non-normative, unauthorized (lawful within
               terms of reuse in the public domain) and not for publication, being intended only for demonstration of
               tools and capabilities.</i></p>
      </section>
      <section>
         <h2>Step one: review projects</h2>
         <p>These projects follow the general pattern in this repository. It is designed to be operated on its own, and
            comes with pipelines to be run to acquire resources from the Internet, typically placing these in the
            project lib directory . Such resources may include data sources or other dependencies for steps in the
            pipeline. It is always a good idea to look at pipelines before you run them, in case such requirements must
            be addressed first.</p>
         <section>
            <h3>USDS Playbook</h3>
            <p>This is the simplest and smallest of the OSCAL production demonstrations. It reads a web page and
               converts its contents into a simple but complete <a
                  href="https://pages.nist.gov/OSCAL/resources/concepts/layer/control/catalog/">OSCAL catalog</a>.</p>
            <p>The web source for this transformation has been archived and committed to this repository to ensure the
               demonstration works even if the upstream data source changes or becomes unavailable. Naturally, change
               management in the face of such potentials is an important issue. Fortunately, XProc gives us ways of both
               detecting and adapting to changes in the operating context or environment, as demonstrated (in a simple
               way) on these projects.</p>
         </section>
         <section>
            <h3>NIST CPRT SP 800-171</h3>
            <p>The data set source for this OSCAL is JSON available through a public portal, the <a
                  href="https://csrc.nist.gov/Projects/cprt">Cybersecurity and Privacy Reference Tool</a> maintained by
               the National Institute of Standards and Technology (NIST).</p>
            <p>Again producing an OSCAL catalog, this project has real-world complexity. <i>Note that neither this
                  production nor its OSCAL representation are canonical or authoritative</i>, and should not be used for
               security operations, being untested in that context. (Instead, use XProc to build and maintain your own
               feeds from the source.)</p>
            <p>The pipeline that produces this OSCAL also demonstrates how a pipeline can include validations of its
               own, supporting quality checking by means of schemas and queries over data as it passes through the
               system.</p>
         </section>
         <section>
            <h3>US Army FM 6-22, chapter 4</h3>
            <p>This example is somewhat fanciful or artificial, as the source data was not produced with OSCAL in mind.
               Given this mismatch, that it works at all might be considered noteworthy, much less how well it
               works.</p>
            <p><a href="https://armypubs.army.mil/epubs/DR_pubs/DR_a/ARN36735-FM_6-22-000-WEB-1.pdf">US Army Field
                  Manual 6-22</a> on <b>Developing Leaders</b> has a distinguished history and distills hard-won
               knowledge, with many dedicated contributors over many revisions, and is noteworthy for this reason alone.
               As a structured data set, Chapter 4 of this document serves as a startling demonstration of how OSCAL can
               support <q>semantic description</q> of written (and typeset) information that shows OSCAL-like
               regularities, even when it has not been created with OSCAL in mind. As a machine-readable, structured,
               validable data instance, FM 6-22 and its contents may be useful in multiple ways beyond (simple)
               publication in print and PDF – while those capabilities have not been abandoned. At the same time the
               OSCAL-encoded version is suggestive of entirely new functionalities.</p>
            <p>Greater accessibility is the goal, considered broadly. A standard such as OSCAL encoding is useful
               insofar as it serves that goal.</p>
            <p>Of the three demonstrations, this is the most complex, requiring not only generic transformation logic,
               but also ad-hoc analysis with patches, in order to rectify encoding problems in the source. XProc
               provides tools and methods for this careful work that are efficient, comprehensive, manageable and
               testable.</p>
         </section>
      </section>
      <section>
         <h2>Step two: Examine pipelines and inputs</h2>
         <section>
            <h3>USDS Playbook</h3>
            <p>Three pipelines can be found in this project folder:</p>
            <ul>
               <li><a href="../../../projects/oscal-import/USDS-2024_Playbook/GRAB-PLAYBOOK.xpl">GRAB-PLAYBOOK</a> copies an HTML
                  file from the Internet (USDS web site) and saves it locally in an <code>archive</code> folder as <a
                     href="../../../projects/oscal-import/USDS-2024_Playbook/archive/playbook-source.html"
                  >playbook-source.html</a></li>
               <li><a href="../../../projects/oscal-import/USDS-2024_Playbook/GRAB-RESOURCES.xpl">GRAB-RESOURCES.xpl</a> acquires a
                  copy of the OSCAL Catalog XSD schema, for validating outputs</li>
               <li><a href="../../../projects/oscal-import/USDS-2024_Playbook/OSCAL-PLAYBOOK.xpl">OSCAL-PLAYBOOK.xpl</a> runs a
                  pipeline converting the saved HTML file into an OSCAL file, validating it, and saving it as file <a
                     href="../../../projects/oscal-import/USDS-2024_Playbook/archive/playbook_99_oscal.xml"
                     >playbook_99_oscal.xml</a></li>
            </ul>
            <p>If pipelines have been run, there will also be files in the <a
                  href="../../../projects/oscal-import/USDS-2024_Playbook/lib/">lib</a> and <a
                  href="../../../projects/oscal-import/USDS-2024_Playbook/archive/">archive</a> directories. The <a
                  href="../../../projects/oscal-import/USDS-2024_Playbook/src/">src</a> directory contains other files used by the
               XProc.</p>
            <p>As a general rule of good practice, XProc pipelines in this pipeline always emit messages to the console
               when saving copies of files it downloads.</p>
         </section>
         <section>
            <h3>NIST CPRT SP 800-171</h3>
            <p>The JSON source data for this demonstration has been downloaded and saved in its<a
                  href="../../../projects/oscal-import/NIST-CPRT/data/cprt/cprt_SP_800_171_3_0_0_11-12-2024.json">data/cprt</a>
               directory. This file file is bound to the <code>source</code> port of the single pipeline in this
               project: <a href="../../../projects/oscal-import/NIST-CPRT/PRODUCE_SP800-171-OSCAL.xpl"
                  >PRODUCE_SP800-171-OSCAL.xpl</a>.</p>
            <p>The <a href="../../../projects/CPRT-import/src/">src</a> directory in this project folder contains a
               number of resources required by the pipeline, including both XSLT transformations and rule sets (using
               Schematron and RelaxNG) to be used as part of pipeline execution, ensuring predictability, conformance
               and correctness.</p>
         </section>
         <section>
            <h3>US Army FM 6-22, chapter 4</h3>
            <p>The pipeline <a href="../../../projects/oscal-import/USArmy_FM6-22/PRODUCE_FM6-22-chapter4.xpl"
                  >PRODUCE_FM6-22-chapter4.xpl</a> starts by reading an HTML data file created by using utility software
               to produce a <q>web page export</q> of the document in its original PDF format, as published by the US
               Army and placed into the public domain. This prior step must be accomplished by hand, and is sensitive to
               the software used. Consequently, for this pipeline to be reproducible as a demonstration, the HTML input
               needs to be fixed. This HTML has been saved as file <a
                  href="../../../projects/oscal-import/USArmy_FM6-22/source/export/fm6_22.html">fm6_22.html</a>. An additional copy
               with whitespace added for legibility is placed alongside it.</p>
            <p>Additionally, the pipeline requires other resources to be stored in <code>lib</code>, again acquired by
               running pipelines: <a href="../../../projects/oscal-import/USArmy_FM6-22/GRAB-RESOURCES.xpl">GRAB-RESOURCES.xpl</a>
               for a local copy of the OSCAL schema and <a href="../../../projects/oscal-import/USArmy_FM6-22/GRAB-NISO_STS-RNG.xpl"
                  >GRAB-NISO_STS-RNG.xpl</a> to acquire a RelaxNG schema for NISO STS format.</p>
            <p>This last resource is needed by the pipeline because it produces, in addition to OSCAL, <a
                  href="../../../projects/oscal-import/USArmy_FM6-22/temp/t06_sts-enhanced.xml">a version of the Field Manual encoded
                  in STS XML</a> as a waypoint format before creating OSCAL. This XML is of interest in its own right,
               as it is valid STS XML - try an <a href="https://pages.nist.gov/xslt-blender/sts-viewer/">STS Viewer</a>
               to see the code rendered.</p>
         </section>
      </section>
      <section>
         <h2>Step three: Run pipelines, inspect results</h2>
         <p>Interim or final result files produced by these pipelines may have been committed to the repository, in
            which case they can be inspected without running the pipeline.</p>
         <p>However, running each pipeline guarantee for the operator that you are seeing what you think you are
            seeing.</p>
         <section>
            <h3>USDS Playbook</h3>
            <p>As noted, and once all preliminaries are in place, the pipeline <a
                  href="../../../projects/oscal-import/USDS-2024_Playbook/OSCAL-PLAYBOOK.xpl">OSCAL-PLAYBOOK.xpl</a> will read the
               HTML source file and translate it into OSCAL.</p>
            <p>Assuming all resources are in place, this pipeline should produce several files in an
                  <code>archive</code> directory. In particular, look for a <q>terminal file</q> in OSCAL format, for
               example, named <code>playbook_99_oscal.xml</code>.</p>
            <p>For this pipeline to work, other pipelines may have to be run first, to acquire resources: see the
               project <a href="../../../projects/oscal-import/USDS-2024_Playbook/readme.md">readme.md</a> document.</p>
         </section>
         <section>
            <h3>NIST CPRT SP 800-171</h3>
            <p>Running <a href="../../../projects/oscal-import/NIST-CPRT/PRODUCE_SP800-171-OSCAL.xpl">this pipeline </a> creates
               interim results in a <code>temp</code> directory, for tracing and debugging, overwriting copies of these
               files already present. A <i>fresh</i> output file with a new (distinct) name including an ID segment (the
               first block of its top-level UUID) is also produced in the project folder.</p>
            <p>In operation, a user would delete files produced by <q>practice runs</q>: feel free to do this as
               well.</p>
            <p>Note that OSCAL files produced by this pipeline in separate runtimes will not be identical, if only
               because each one has its own timestamp with its creation date. Otherwise, the same sources should produce
               the same results – and this can be tested.</p>
         </section>
         <section>
            <h3>US Army FM 6-22, chapter 4</h3>
            <p>As noted above, this pipeline starts by loading <a
                  href="../../../projects/oscal-import/USArmy_FM6-22/source/export/fm6_22.html">source/export/fm6_22.html</a>.</p>
            <p>This pipeline produces temporary results along with its final result file, a valid OSCAL catalog.</p>
            <section>
               <h4>Pipeline results</h4>
               <p>A directory named <code>temp</code> will contain results of this pipeline.</p>
               <p>These include both interim results and nominally <q>final</q> outputs of the pipeline, including both
                  OSCAL and NISO STS XML outputs: that is, the same data in two different forms. These are interesting
                  for the comparison they provide – and the STS version is potentially useful in itself.</p>
            </section>
            <section>
               <h4>OSCAL output</h4>
               <p>Additionally, a file <a href="../../../projects/oscal-import/USArmy_FM6-22/FM_6-22-OSCAL-working.xml"
                     >FM_6-22-OSCAL-working.xml</a> presents a copy of the OSCAL version (also saved in
                     <code>temp</code>) with an XML stylesheet processing instruction attached. This binding makes it
                  possible to view this file with formatting, when served by a web server. (See the next lesson unit for
                  more details.)</p>
               <p>OSCAL (Open Security Controls Assessment Language) is able to factor out a rich <q>semantic</q> view
                  of this information set, presenting the full text of Chapter 4, but this time along with externalized
                  control sets derived from their tables. These represent 25 <b>attributes</b> and 50
                     <b>competencies</b>, as described in Field Manual 6-22 and its related documents such as ADP 6-22
                  (describing the <b>US Army Leadership Requirements Model</b>).</p>
            </section>
         </section>
      </section>
      <section>
         <h2>Step four: Inspect again in diagnostic mode</h2>
         <p>Having run these pipelines and seen their sources and results, inspect them one more time to appreciate some
            of their features.</p>
         <section>
            <h3>USDS Playbook</h3>
            <p>This XProc is a little unusual in that while its conversion requirements are fairly simple, it has been
               built defensively, with fallback logic to handle cases of missing or broken inputs. If inputs are missing
               – either the source data, or the OSCAL schema to which it is expected to validate – the pipeline does not
               error out, but instead delivers a more helpful response including instructions on acquiring them.
               Similarly, if the transformation process itself changes without notice, some defensive validation built
               into this pipeline will fail.</p>
            <p>All this takes the form of extra complexity using elements such as <code>p:choose</code> (for
               conditional, switch-statement-like branching) along with validation steps.</p>
            <p><a href="../../../projects/oscal-import/USDS-2024_Playbook/OSCAL-PLAYBOOK-SIMPLE.xpl">A simpler version of this
                  pipeline</a>without the defensive logic is saved next to it – compare (and run) this pipeline for
               comparison.</p>
         </section>
         <section>
            <h3>NIST CPRT SP 800-171</h3>
            <p>The pipeline that produces this OSCAL is somewhat more complex because its source data, in JSON format,
               is noisier and rougher, and requires somewhat more aggressive normalization and regularization.
               Accordingly, the pipeline does some work based on values provided to match the expectations of the
               source. Those values are provided to the XProc process as options, which can be set at runtime. While
               they are not expected to be any different from the set values for this data set, exposing them as options
               makes it easier to find and change them if this pipeline is ever adjusted to handle inputs that are
               nearly the same, but not exactly the same, as the source data here.</p>
            <p>Internally, this pipeline does some fairly extensive string processing to render information that is
               given implicitly by means of a bespoke (one-off) syntax. Unless your XPath is strong you may wish to
               compare inputs and outputs of specific steps directly, in order to understand better what they do.</p>
            <p>The steps in this pipeline are also organized into two large groups (using <code>p:group</code>) in order
               to separate them functionally. First, the data is ingested into a declarative, semantic-descriptive
               XML-based format. Then it is cast to OSCAL. Each of these processes requires several steps.</p>
         </section>
         <section>
            <h3>US Army FM 6-22, chapter 4</h3>
            <p>As noted above, both OSCAL and STS XML outputs may be considered valuable resources. In this case, STS is
               used as the <q>pivot</q>, while the OSCAL output is richer and information-denser (about 80% the size in
               kilobytes). Either may be suitable for producing formatted results.</p>
            <p>Additionally, this pipeline has a <b>pipeline option</b> declared named <code>writing-all</code>. When
               set to <code>true()</code>, the processor will be instructed to save intermediate results of pipeline
               processing in the <code>temp</code> directory. These are numbered in sequence. A <code>diff</code> tool
               (especially an XML-aware diff) between successive forms will reveal exactly what changes between these
               forms.</p>
            <p>Set this option by hard-coding in the pipeline or by using your processor's option syntax:</p>
            <ul>
               <li><a href="https://www.xml-project.com/manual/ch01.html#R_ch1_s1_2_s2_3">Morgana XProc IIIse</a>
                  supports syntax in the form <code>-option:OPTIONNAME=optionvalue</code> from the command line</li>
               <li><a href="https://docs.xmlcalabash.com/userguide/current/running.html#run-run">XML Calabash 3</a>
                  supports syntax in the form <code>OPTIONNAME=optionvalue</code>
                  <i>after</i> the pipeline name in the command</li>
            </ul>
         </section>
      </section>
      <section>
         <h2>What these pipelines have in common</h2>
         <p>XXX See the Learner lesson unit for remarks on the patterns that can be observed in these pipelines.</p>
         <ul>
            <li>Entropy-removing upconversion to semantic target, followed by downhill conversion - declarative encoding
               as 'potential energy' magnified by the degree to which consumers have prior knowledge of formats</li>
            <li>Mix of generic and ad-hoc processes (even tailored per pipeline)</li>
            <li>XProc or XSLT? (Or XQuery?) XSLT, in line or out of line?</li>
            <li>Transparency and traceability of deterministic, well-defined and specified processes</li>
            <li>Scaling and scalability: complexity, throughput (quantity), variability, time horizons - testing one-off
               cases vs production pipelines</li>
         </ul>
      </section>
      <section>
         <h2>Some differences</h2>
         <p>Pipelines will vary in how much error handling or implicit <q>hand holding</q> they offer. The USDS Playbook
            example shows a case that may arguably be over-engineered, in the sense that it provides more complex
            fallback logic than the (comparatively simple) problem may warrant. For example, instead of declaring
            expected inputs (which can be checked when the pipeline is loaded), it loads them dynamically, giving a
            custom error message when they are missing (with a hint on how they can be acquired). A simpler pipeline
            might trust the processor's own error message to do the job of communicating the problem. The benefit is
            that this shows how XProc pipelines can be made to be more forgiving (of predictable errors) as well as
            presumably easier for the user, at the cost of some logical complexity in its internals.</p>
         <p>Nevertheless even a pipeline designed to be robust will not when required inputs are not available. An
            engine drives a cart, but we move the cart for the sake of its cargo: this is what is means to be
               <q>required</q>.</p>
      </section>
   </body>
</html>